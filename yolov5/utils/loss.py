# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
"""
Loss functions
"""

import torch
import torch.nn as nn

from utils.metrics import bbox_iou
from utils.torch_utils import is_parallel


def smooth_BCE(eps=0.1):  # å‚è€ƒé“¾æ¥: https://github.com/ultralytics/yolov3/issues/238#issuecomment-598028441
    # è¿”å›å¹³æ»‘çš„æ­£è´Ÿæ ‡ç­¾ï¼Œé€‚ç”¨äºäºŒå…ƒäº¤å‰ç†µï¼ˆBCEï¼‰æŸå¤±
    return 1.0 - 0.5 * eps, 0.5 * eps  # æ­£æ ‡ç­¾å’Œè´Ÿæ ‡ç­¾çš„å¹³æ»‘å€¼



class BCEBlurWithLogitsLoss(nn.Module):
    # è‡ªå®šä¹‰çš„äºŒå…ƒäº¤å‰ç†µæŸå¤±ï¼Œç»“åˆäº† logits å’Œæ ‡ç­¾å¹³æ»‘å¤„ç†ï¼Œå‡å°‘ç¼ºå¤±æ ‡ç­¾çš„å½±å“
    def __init__(self, alpha=0.05):
        super(BCEBlurWithLogitsLoss, self).__init__()
        self.loss_fcn = nn.BCEWithLogitsLoss(reduction='none')  # å¿…é¡»ä½¿ç”¨ nn.BCEWithLogitsLoss()
        self.alpha = alpha  # å¹³æ»‘å› å­

    def forward(self, pred, true):
        loss = self.loss_fcn(pred, true)  # è®¡ç®—æŸå¤±
        pred = torch.sigmoid(pred)  # ä» logits è½¬æ¢ä¸ºæ¦‚ç‡
        dx = pred - true  # è®¡ç®—é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„å·®å¼‚
        # dx = (pred - true).abs()  # è®¡ç®—ç»å¯¹å·®å¼‚ï¼Œå¯é€‰ï¼šå‡å°‘ç¼ºå¤±æ ‡ç­¾å’Œé”™è¯¯æ ‡ç­¾çš„å½±å“
        alpha_factor = 1 - torch.exp((dx - 1) / (self.alpha + 1e-4))  # è®¡ç®— alpha å› å­
        loss *= alpha_factor  # åŠ æƒæŸå¤±
        return loss.mean()  # è¿”å›å¹³å‡æŸå¤±



class FocalLoss(nn.Module):
    # åŒ…è£…ç„¦ç‚¹æŸå¤±ï¼Œç”¨äºåœ¨ç°æœ‰æŸå¤±å‡½æ•°ä¸Šåº”ç”¨ç„¦ç‚¹æŸå¤±ï¼Œä¾‹ï¼šcriteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)
    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):
        super(FocalLoss, self).__init__()
        self.loss_fcn = loss_fcn  # å¿…é¡»æ˜¯ nn.BCEWithLogitsLoss()
        self.gamma = gamma  # ç„¦ç‚¹å› å­
        self.alpha = alpha  # æƒé‡å› å­
        self.reduction = loss_fcn.reduction  # ä¿å­˜åŸå§‹çš„å½’çº¦æ–¹å¼
        self.loss_fcn.reduction = 'none'  # éœ€è¦å¯¹æ¯ä¸ªå…ƒç´ åº”ç”¨ç„¦ç‚¹æŸå¤±

    def forward(self, pred, true):
        loss = self.loss_fcn(pred, true)  # è®¡ç®—åŸºç¡€æŸå¤±
        # p_t = torch.exp(-loss)  # è®¡ç®—é¢„æµ‹æ¦‚ç‡ï¼Œæ³¨é‡Šæ‰çš„å®ç°æ–¹å¼
        # loss *= self.alpha * (1.000001 - p_t) ** self.gamma  # ä½¿ç”¨éé›¶å¹‚ä»¥ä¿æŒæ¢¯åº¦ç¨³å®š

        # TensorFlow å®ç°å‚è€ƒ https://github.com/tensorflow/addons/blob/v0.7.1/tensorflow_addons/losses/focal_loss.py
        pred_prob = torch.sigmoid(pred)  # ä» logits è½¬æ¢ä¸ºæ¦‚ç‡
        p_t = true * pred_prob + (1 - true) * (1 - pred_prob)  # è®¡ç®— p_t
        alpha_factor = true * self.alpha + (1 - true) * (1 - self.alpha)  # è®¡ç®— alpha å› å­
        modulating_factor = (1.0 - p_t) ** self.gamma  # è®¡ç®—è°ƒåˆ¶å› å­
        loss *= alpha_factor * modulating_factor  # åº”ç”¨ç„¦ç‚¹æŸå¤±

        if self.reduction == 'mean':
            return loss.mean()  # è¿”å›å¹³å‡æŸå¤±
        elif self.reduction == 'sum':
            return loss.sum()  # è¿”å›æ€»æŸå¤±
        else:  # 'none'
            return loss  # è¿”å›æœªå½’çº¦æŸå¤±


class QFocalLoss(nn.Module):
    # åŒ…è£…è´¨é‡ç„¦ç‚¹æŸå¤±ï¼Œç”¨äºåœ¨ç°æœ‰æŸå¤±å‡½æ•°ä¸Šåº”ç”¨è´¨é‡ç„¦ç‚¹æŸå¤±ï¼Œä¾‹ï¼šcriteria = QFocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)
    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):
        super(QFocalLoss, self).__init__()
        self.loss_fcn = loss_fcn  # å¿…é¡»æ˜¯ nn.BCEWithLogitsLoss()
        self.gamma = gamma  # ç„¦ç‚¹å› å­
        self.alpha = alpha  # æƒé‡å› å­
        self.reduction = loss_fcn.reduction  # ä¿å­˜åŸå§‹çš„å½’çº¦æ–¹å¼
        self.loss_fcn.reduction = 'none'  # éœ€è¦å¯¹æ¯ä¸ªå…ƒç´ åº”ç”¨ç„¦ç‚¹æŸå¤±

    def forward(self, pred, true):
        loss = self.loss_fcn(pred, true)  # è®¡ç®—åŸºç¡€æŸå¤±

        pred_prob = torch.sigmoid(pred)  # ä» logits è½¬æ¢ä¸ºæ¦‚ç‡
        alpha_factor = true * self.alpha + (1 - true) * (1 - self.alpha)  # è®¡ç®— alpha å› å­
        modulating_factor = torch.abs(true - pred_prob) ** self.gamma  # è®¡ç®—è°ƒåˆ¶å› å­
        loss *= alpha_factor * modulating_factor  # åº”ç”¨è´¨é‡ç„¦ç‚¹æŸå¤±

        if self.reduction == 'mean':
            return loss.mean()  # è¿”å›å¹³å‡æŸå¤±
        elif self.reduction == 'sum':
            return loss.sum()  # è¿”å›æ€»æŸå¤±
        else:  # 'none'
            return loss  # è¿”å›æœªå½’çº¦æŸå¤±


class ComputeLoss:
    # è®¡ç®—æŸå¤±çš„ç±»
    def __init__(self, model, autobalance=False):
        self.sort_obj_iou = False  # æ˜¯å¦å¯¹ç›®æ ‡IoUè¿›è¡Œæ’åº
        device = next(model.parameters()).device  # è·å–æ¨¡å‹è®¾å¤‡
        h = model.hyp  # è·å–è¶…å‚æ•°

        # å®šä¹‰æŸå¤±å‡½æ•°
        BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device))  # ç±»åˆ«æŸå¤±
        BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device))  # ç›®æ ‡æŸå¤±

        # ç±»åˆ«æ ‡ç­¾å¹³æ»‘å¤„ç†
        self.cp, self.cn = smooth_BCE(eps=h.get('label_smoothing', 0.0))  # æ­£è´ŸBCEç›®æ ‡

        # ç„¦ç‚¹æŸå¤±
        g = h['fl_gamma']  # ç„¦ç‚¹æŸå¤±çš„gammaå€¼
        if g > 0:
            BCEcls, BCEobj = FocalLoss(BCEcls, g), FocalLoss(BCEobj, g)  # åº”ç”¨ç„¦ç‚¹æŸå¤±

        det = model.module.model[-1] if is_parallel(model) else model.model[-1]  # è·å–æ£€æµ‹æ¨¡å—
        # è®¾å®šæŸå¤±å¹³è¡¡å› å­ï¼Œæ ¹æ®æ£€æµ‹å±‚æ•°ï¼ˆP3-P7ï¼‰
        self.balance = {3: [4.0, 1.0, 0.4]}.get(det.nl, [4.0, 1.0, 0.25, 0.06, .02])
        self.ssi = list(det.stride).index(16) if autobalance else 0  # strideä¸º16çš„ç´¢å¼•
        self.BCEcls, self.BCEobj, self.gr, self.hyp, self.autobalance = BCEcls, BCEobj, 1.0, h, autobalance

        # å°†æ£€æµ‹æ¨¡å—çš„å‚æ•°èµ‹å€¼ç»™è®¡ç®—æŸå¤±ç±»çš„å±æ€§
        for k in 'na', 'nc', 'nl', 'anchors':
            setattr(self, k, getattr(det, k))

    def __call__(self, p, targets):  # predictions, targets, model
        device = targets.device  # è·å–ç›®æ ‡çš„è®¾å¤‡
        # åˆå§‹åŒ–æŸå¤±å€¼
        lcls, lbox, lobj = torch.zeros(1, device=device), torch.zeros(1, device=device), torch.zeros(1, device=device)
        # æ„å»ºç›®æ ‡
        tcls, tbox, indices, anchors = self.build_targets(p, targets)  # targets

        # è®¡ç®—æŸå¤±
        for i, pi in enumerate(p):  # éå†æ¯ä¸ªå±‚çš„é¢„æµ‹
            b, a, gj, gi = indices[i]  # è·å–å›¾åƒã€é”šæ¡†ã€ç½‘æ ¼yåæ ‡å’Œç½‘æ ¼xåæ ‡
            tobj = torch.zeros_like(pi[..., 0], device=device)  # åˆå§‹åŒ–ç›®æ ‡å¯¹è±¡

            n = b.shape[0]  # è·å–ç›®æ ‡æ•°é‡
            if n:  # å¦‚æœæœ‰ç›®æ ‡
                ps = pi[b, a, gj, gi]  # è·å–ä¸ç›®æ ‡å¯¹åº”çš„é¢„æµ‹å­é›†

                # å›å½’æŸå¤±
                pxy = ps[:, :2].sigmoid() * 2. - 0.5  # é¢„æµ‹çš„ä¸­å¿ƒç‚¹
                pwh = (ps[:, 2:4].sigmoid() * 2) ** 2 * anchors[i]  # é¢„æµ‹çš„å®½é«˜
                pbox = torch.cat((pxy, pwh), 1)  # ç»„åˆä¸ºé¢„æµ‹æ¡†
                iou = bbox_iou(pbox.T, tbox[i], x1y1x2y2=False, CIoU=True)  # è®¡ç®—é¢„æµ‹æ¡†ä¸ç›®æ ‡æ¡†çš„IoU
                lbox += (1.0 - iou).mean()  # ç´¯åŠ IoUæŸå¤±

                # ç›®æ ‡ç½®ä¿¡åº¦æŸå¤±
                score_iou = iou.detach().clamp(0).type(tobj.dtype)  # å¤„ç†IoUå¾—åˆ†
                if self.sort_obj_iou:  # å¦‚æœéœ€è¦æ’åº
                    sort_id = torch.argsort(score_iou)
                    b, a, gj, gi, score_iou = b[sort_id], a[sort_id], gj[sort_id], gi[sort_id], score_iou[sort_id]
                tobj[b, a, gj, gi] = (1.0 - self.gr) + self.gr * score_iou  # è®¡ç®—ç›®æ ‡ç½®ä¿¡åº¦

                # åˆ†ç±»æŸå¤±
                if self.nc > 1:  # å¦‚æœæœ‰å¤šä¸ªç±»åˆ«
                    t = torch.full_like(ps[:, 5:], self.cn, device=device)  # åˆå§‹åŒ–ç›®æ ‡
                    t[range(n), tcls[i]] = self.cp  # è®¾ç½®æ­£æ ·æœ¬
                    lcls += self.BCEcls(ps[:, 5:], t)  # è®¡ç®—åˆ†ç±»çš„BCEæŸå¤±

                # ç›®æ ‡è®°å½•ï¼ˆæ³¨é‡Šæ‰çš„éƒ¨åˆ†ï¼‰
                # with open('targets.txt', 'a') as file:
                #     [file.write('%11.5g ' * 4 % tuple(x) + '\n') for x in torch.cat((txy[i], twh[i]), 1)]

            # è®¡ç®—ç›®æ ‡ç½®ä¿¡åº¦æŸå¤±
            obji = self.BCEobj(pi[..., 4], tobj)
            lobj += obji * self.balance[i]  # ç´¯åŠ å¯¹è±¡æŸå¤±
            if self.autobalance:  # è‡ªåŠ¨å¹³è¡¡æŸå¤±
                self.balance[i] = self.balance[i] * 0.9999 + 0.0001 / obji.detach().item()

        # è‡ªåŠ¨å¹³è¡¡æŸå¤±
        if self.autobalance:
            self.balance = [x / self.balance[self.ssi] for x in self.balance]
        # æ ¹æ®è¶…å‚æ•°ç¼©æ”¾æŸå¤±
        lbox *= self.hyp['box']
        lobj *= self.hyp['obj']
        lcls *= self.hyp['cls']
        bs = tobj.shape[0]  # è·å–æ‰¹å¤§å°

        return (lbox + lobj + lcls) * bs, torch.cat((lbox, lobj, lcls)).detach()  # è¿”å›æ€»æŸå¤±å’Œå„ç±»æŸå¤±

    def build_targets(self, p, targets):
        # ä¸ºcompute_loss()æ„å»ºç›®æ ‡ï¼Œè¾“å…¥æ ¼å¼ä¸ºtargets(image, class, x, y, w, h)
        na, nt = self.na, targets.shape[0]  # é”šæ¡†æ•°é‡å’Œç›®æ ‡æ•°é‡
        tcls, tbox, indices, anch = [], [], [], []  # åˆå§‹åŒ–ç›®æ ‡åˆ†ç±»ã€è¾¹ç•Œæ¡†ã€ç´¢å¼•å’Œé”šæ¡†åˆ—è¡¨
        gain = torch.ones(7, device=targets.device)  # ç”¨äºå½’ä¸€åŒ–åˆ°ç½‘æ ¼ç©ºé—´çš„å¢ç›Š
        ai = torch.arange(na, device=targets.device).float().view(na, 1).repeat(1, nt)  # åˆ›å»ºé”šæ¡†ç´¢å¼•
        targets = torch.cat((targets.repeat(na, 1, 1), ai[:, :, None]), 2)  # è¿½åŠ é”šæ¡†ç´¢å¼•åˆ°ç›®æ ‡

        g = 0.5  # åç§»é‡
        # å®šä¹‰åç§»æ•°ç»„
        off = torch.tensor([[0, 0],
                            [1, 0], [0, 1], [-1, 0], [0, -1]], device=targets.device).float() * g  # åç§»é‡

        for i in range(self.nl):  # éå†æ¯ä¸ªå±‚
            anchors = self.anchors[i]  # è·å–å½“å‰å±‚çš„é”šæ¡†
            gain[2:6] = torch.tensor(p[i].shape)[[3, 2, 3, 2]]  # è·å–xyxyå¢ç›Š

            # å°†ç›®æ ‡ä¸é”šæ¡†åŒ¹é…
            t = targets * gain  # å½’ä¸€åŒ–ç›®æ ‡
            if nt:  # å¦‚æœæœ‰ç›®æ ‡
                # è®¡ç®—å®½é«˜æ¯”
                r = t[:, :, 4:6] / anchors[:, None]  # è®¡ç®—å®½é«˜æ¯”
                j = torch.max(r, 1. / r).max(2)[0] < self.hyp['anchor_t']  # æ¯”è¾ƒå®½é«˜æ¯”
                t = t[j]  # ç­›é€‰åŒ¹é…çš„ç›®æ ‡

                # è®¡ç®—åç§»é‡
                gxy = t[:, 2:4]  # ç½‘æ ¼xyåæ ‡
                gxi = gain[[2, 3]] - gxy  # è®¡ç®—é€†åç§»
                j, k = ((gxy % 1. < g) & (gxy > 1.)).T  # æ£€æŸ¥ç½‘æ ¼åæ ‡
                l, m = ((gxi % 1. < g) & (gxi > 1.)).T  # æ£€æŸ¥é€†ç½‘æ ¼åæ ‡
                j = torch.stack((torch.ones_like(j), j, k, l, m))  # åˆå¹¶æ¡ä»¶
                t = t.repeat((5, 1, 1))[j]  # é‡å¤å¹¶ç­›é€‰ç›®æ ‡
                offsets = (torch.zeros_like(gxy)[None] + off[:, None])[j]  # è®¡ç®—åç§»é‡
            else:
                t = targets[0]  # å¦‚æœæ²¡æœ‰ç›®æ ‡ï¼Œç›´æ¥è·å–
                offsets = 0  # æ— åç§»

            # å®šä¹‰ç›®æ ‡
            b, c = t[:, :2].long().T  # æå–å›¾åƒå’Œç±»åˆ«
            gxy = t[:, 2:4]  # ç½‘æ ¼xyåæ ‡
            gwh = t[:, 4:6]  # ç½‘æ ¼å®½é«˜
            gij = (gxy - offsets).long()  # è®¡ç®—ç½‘æ ¼ç´¢å¼•
            gi, gj = gij.T  # ç½‘æ ¼xyç´¢å¼•

            # è¿½åŠ ç›®æ ‡ä¿¡æ¯
            a = t[:, 6].long()  # é”šæ¡†ç´¢å¼•
            indices.append((b, a, gj.clamp_(0, gain[3] - 1), gi.clamp_(0, gain[2] - 1)))  # ä¿å­˜å›¾åƒã€é”šæ¡†å’Œç½‘æ ¼ç´¢å¼•
            tbox.append(torch.cat((gxy - gij, gwh), 1))  # ä¿å­˜è¾¹ç•Œæ¡†ä¿¡æ¯
            anch.append(anchors[a])  # ä¿å­˜é”šæ¡†
            tcls.append(c)  # ä¿å­˜ç±»åˆ«

        return tcls, tbox, indices, anch  # è¿”å›ç›®æ ‡åˆ†ç±»ã€è¾¹ç•Œæ¡†ã€ç´¢å¼•å’Œé”šæ¡†
