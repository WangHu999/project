# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
"""
General utils
"""

import contextlib
import glob
import logging
import math
import os
import platform
import random
import re
import signal
import time
import urllib
from itertools import repeat
from multiprocessing.pool import ThreadPool
from pathlib import Path
from subprocess import check_output
from zipfile import ZipFile

import cv2
import numpy as np
import pandas as pd
import pkg_resources as pkg
import torch
import torchvision
import yaml

from utils.downloads import gsutil_getsize
from utils.metrics import box_iou, fitness

# Settings
torch.set_printoptions(linewidth=320, precision=5, profile='long')
# è®¾ç½® PyTorch è¾“å‡ºé€‰é¡¹ï¼š
# linewidth: è®¾ç½®æ¯è¡Œçš„æœ€å¤§å®½åº¦ä¸º 320 ä¸ªå­—ç¬¦
# precision: è®¾ç½®æµ®ç‚¹æ•°çš„ç²¾åº¦ä¸º 5 ä½
# profile: è®¾ç½®ä¸º 'long'ï¼Œä»¥ä¾¿è·å¾—æ›´è¯¦ç»†çš„è¾“å‡ºæ ¼å¼

np.set_printoptions(linewidth=320, formatter={'float_kind': '{:11.5g}'.format})
# è®¾ç½® NumPy è¾“å‡ºé€‰é¡¹ï¼š
# linewidth: è®¾ç½®æ¯è¡Œçš„æœ€å¤§å®½åº¦ä¸º 320 ä¸ªå­—ç¬¦
# formatter: ä¸ºæµ®ç‚¹æ•°è®¾ç½®è¾“å‡ºæ ¼å¼ï¼Œä½¿ç”¨çŸ­æ ¼å¼ï¼ˆæœ€å¤š 5 ä½æœ‰æ•ˆæ•°å­—ï¼‰

pd.options.display.max_columns = 10
# è®¾ç½® Pandas æ˜¾ç¤ºé€‰é¡¹ï¼š
# max_columns: é™åˆ¶åœ¨ DataFrame ä¸­æœ€å¤šæ˜¾ç¤º 10 åˆ—

cv2.setNumThreads(0)
# è®¾ç½® OpenCV çš„çº¿ç¨‹æ•°ä¸º 0ï¼Œé˜²æ­¢å…¶ä½¿ç”¨å¤šçº¿ç¨‹
# è¿™é¿å…äº†ä¸ PyTorch DataLoader å‘ç”Ÿä¸å…¼å®¹é—®é¢˜

os.environ['NUMEXPR_MAX_THREADS'] = str(min(os.cpu_count(), 8))
# è®¾ç½® NumExpr çš„æœ€å¤§çº¿ç¨‹æ•°ï¼š
# æ ¹æ®å¯ç”¨çš„ CPU æ ¸å¿ƒæ•°ï¼ˆæœ€å¤šä¸º 8ï¼‰æ¥é™åˆ¶çº¿ç¨‹æ•°

FILE = Path(__file__).resolve()
# è·å–å½“å‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼Œå¹¶è¿”å›ä¸€ä¸ª Path å¯¹è±¡

ROOT = FILE.parents[1]
# è®¾ç½®æ ¹ç›®å½•ä¸ºå½“å‰æ–‡ä»¶çš„çˆ¶ç›®å½•çš„çˆ¶ç›®å½•ï¼Œå³ YOLOv5 çš„æ ¹ç›®å½•


class Profile(contextlib.ContextDecorator):
    """
    Profile classç”¨äºæ€§èƒ½åˆ†æï¼Œæ—¢å¯ä»¥ä½œä¸ºè£…é¥°å™¨ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥ä½œä¸ºä¸Šä¸‹æ–‡ç®¡ç†å™¨ã€‚

    Usage:
        @Profile()  # ç”¨ä½œè£…é¥°å™¨
        or
        with Profile():  # ç”¨ä½œä¸Šä¸‹æ–‡ç®¡ç†å™¨
    """

    def __enter__(self):
        """
        ä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„å…¥å£æ–¹æ³•ã€‚
        åœ¨è¿›å…¥ä¸Šä¸‹æ–‡æ—¶è®°å½•å½“å‰æ—¶é—´ã€‚
        """
        self.start = time.time()  # è®°å½•å½“å‰æ—¶é—´æˆ³

    def __exit__(self, type, value, traceback):
        """
        ä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„å‡ºå£æ–¹æ³•ã€‚
        åœ¨é€€å‡ºä¸Šä¸‹æ–‡æ—¶è®¡ç®—å¹¶æ‰“å°è€—æ—¶ã€‚

        Arguments:
            type: å¼‚å¸¸ç±»å‹ï¼ˆå¦‚æœæœ‰å¼‚å¸¸å‘ç”Ÿï¼‰
            value: å¼‚å¸¸å€¼
            traceback: å¼‚å¸¸è¿½è¸ªå¯¹è±¡
        """
        # è®¡ç®—è€—æ—¶å¹¶æ‰“å°ç»“æœï¼Œä¿ç•™5ä½å°æ•°
        print(f'Profile results: {time.time() - self.start:.5f}s')


class Timeout(contextlib.ContextDecorator):
    """
    Timeout ç±»ç”¨äºè®¾ç½®è¶…æ—¶æœºåˆ¶ï¼Œæ—¢å¯ä»¥ä½œä¸ºè£…é¥°å™¨ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥ä½œä¸ºä¸Šä¸‹æ–‡ç®¡ç†å™¨ã€‚

    Usage:
        @Timeout(seconds)  # ç”¨ä½œè£…é¥°å™¨
        or
        with Timeout(seconds):  # ç”¨ä½œä¸Šä¸‹æ–‡ç®¡ç†å™¨
    """

    def __init__(self, seconds, *, timeout_msg='', suppress_timeout_errors=True):
        """
        åˆå§‹åŒ– Timeout ç±»çš„å®ä¾‹ã€‚

        Arguments:
            seconds: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            timeout_msg: è¶…æ—¶åæŠ›å‡ºçš„æ¶ˆæ¯ï¼ˆå¯é€‰ï¼‰
            suppress_timeout_errors: æ˜¯å¦æŠ‘åˆ¶ TimeoutErrorï¼ˆé»˜è®¤ä¸º Trueï¼‰
        """
        self.seconds = int(seconds)  # å°†è¶…æ—¶ç§’æ•°è½¬æ¢ä¸ºæ•´æ•°
        self.timeout_message = timeout_msg  # è®¾ç½®è¶…æ—¶æ¶ˆæ¯
        self.suppress = bool(suppress_timeout_errors)  # è®¾ç½®æ˜¯å¦æŠ‘åˆ¶è¶…æ—¶é”™è¯¯

    def _timeout_handler(self, signum, frame):
        """
        è¶…æ—¶ä¿¡å·å¤„ç†å‡½æ•°ï¼ŒæŠ›å‡º TimeoutErrorã€‚

        Arguments:
            signum: ä¿¡å·ç¼–å·
            frame: å½“å‰çš„æ ˆå¸§
        """
        raise TimeoutError(self.timeout_message)  # æŠ›å‡ºè¶…æ—¶å¼‚å¸¸

    def __enter__(self):
        """
        ä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„å…¥å£æ–¹æ³•ã€‚
        åœ¨è¿›å…¥ä¸Šä¸‹æ–‡æ—¶è®¾ç½®è¶…æ—¶å¤„ç†ç¨‹åºå¹¶å¯åŠ¨è®¡æ—¶å™¨ã€‚
        """
        signal.signal(signal.SIGALRM, self._timeout_handler)  # è®¾ç½® SIGALRM çš„å¤„ç†å‡½æ•°
        signal.alarm(self.seconds)  # å¯åŠ¨ SIGALRM è®¡æ—¶å™¨

    def __exit__(self, exc_type, exc_val, exc_tb):
        """
        ä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„å‡ºå£æ–¹æ³•ã€‚
        åœ¨é€€å‡ºä¸Šä¸‹æ–‡æ—¶å–æ¶ˆè®¡æ—¶å™¨ï¼Œå¦‚æœæŠ‘åˆ¶äº†è¶…æ—¶é”™è¯¯ï¼Œåˆ™è¿”å› Trueã€‚

        Arguments:
            exc_type: å¼‚å¸¸ç±»å‹ï¼ˆå¦‚æœæœ‰å¼‚å¸¸å‘ç”Ÿï¼‰
            exc_val: å¼‚å¸¸å€¼
            exc_tb: å¼‚å¸¸è¿½è¸ªå¯¹è±¡
        """
        signal.alarm(0)  # å–æ¶ˆè®¡åˆ’çš„ SIGALRM
        if self.suppress and exc_type is TimeoutError:  # å¦‚æœæŠ‘åˆ¶è¶…æ—¶é”™è¯¯
            return True  # é˜»æ­¢å¼‚å¸¸ä¼ æ’­


def try_except(func):
    """
    try_except è£…é¥°å™¨ç”¨äºæ•è·å¹¶å¤„ç†å‡½æ•°æ‰§è¡Œä¸­çš„å¼‚å¸¸ã€‚

    Usage:
        @try_except
        def my_function():
            # å‡½æ•°ä½“
    """

    def handler(*args, **kwargs):
        """
        è£…é¥°å™¨å†…éƒ¨çš„å¤„ç†å‡½æ•°ï¼Œè´Ÿè´£æ‰§è¡Œè¢«è£…é¥°çš„å‡½æ•°å¹¶æ•è·å¼‚å¸¸ã€‚

        Arguments:
            *args: ä½ç½®å‚æ•°
            **kwargs: å…³é”®å­—å‚æ•°
        """
        try:
            func(*args, **kwargs)  # æ‰§è¡Œè¢«è£…é¥°çš„å‡½æ•°
        except Exception as e:
            print(e)  # æ•è·å¹¶æ‰“å°å¼‚å¸¸

    return handler  # è¿”å›å¤„ç†å‡½æ•°



def methods(instance):
    """
    è·å–ç»™å®šç±»å®ä¾‹çš„æ‰€æœ‰å¯è°ƒç”¨æ–¹æ³•ï¼ˆä¸åŒ…æ‹¬ç‰¹æ®Šæ–¹æ³•ï¼‰ã€‚

    Arguments:
        instance: ä»»ä½•ç±»çš„å®ä¾‹ã€‚

    Returns:
        list: åŒ…å«å®ä¾‹æ–¹æ³•åç§°çš„åˆ—è¡¨ã€‚
    """

    # ä½¿ç”¨ dir() è·å–å®ä¾‹çš„æ‰€æœ‰å±æ€§å’Œæ–¹æ³•åç§°
    return [f for f in dir(instance)
            if callable(getattr(instance, f))  # æ£€æŸ¥å±æ€§æ˜¯å¦å¯è°ƒç”¨
            and not f.startswith("__")]  # è¿‡æ»¤æ‰ç‰¹æ®Šæ–¹æ³•ï¼ˆä»¥åŒä¸‹åˆ’çº¿å¼€å¤´ï¼‰



def set_logging(rank=-1, verbose=True):
    # è®¾ç½®æ—¥å¿—è®°å½•çš„åŸºæœ¬é…ç½®
    logging.basicConfig(
        format="%(message)s",  # æ—¥å¿—è¾“å‡ºæ ¼å¼ï¼Œåªè¾“å‡ºæ¶ˆæ¯å†…å®¹
        level=logging.INFO if (verbose and rank in [-1, 0]) else logging.WARN  # æ ¹æ® verbose å’Œ rank çš„å€¼ç¡®å®šæ—¥å¿—çº§åˆ«
        # å¦‚æœ verbose ä¸º True ä¸” rank æ˜¯ -1 æˆ– 0ï¼Œåˆ™è®¾ç½®ä¸º INFO çº§åˆ«ï¼ˆæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼‰
        # å¦åˆ™è®¾ç½®ä¸º WARN çº§åˆ«ï¼ˆåªæ˜¾ç¤ºè­¦å‘ŠåŠä»¥ä¸Šçº§åˆ«çš„ä¿¡æ¯ï¼‰
    )



def print_args(name, opt):
    # æ‰“å°è§£æçš„å‘½ä»¤è¡Œå‚æ•°
    # ä½¿ç”¨ colorstr å‡½æ•°ç»™è¾“å‡ºå†…å®¹æ·»åŠ é¢œè‰²ï¼Œæ–¹ä¾¿è¾¨è¯†
    # f'{name}: 'è¡¨ç¤ºæ‰“å°ä¼ å…¥çš„nameå˜é‡ï¼ˆä¸€èˆ¬ä¸ºæ–‡ä»¶åï¼‰ï¼Œä¹‹åç”¨é€—å·åˆ†éš”æ‰“å°æ‰€æœ‰å‚æ•°åŠå…¶å¯¹åº”çš„å€¼
    print(colorstr(f'{name}: ') + ', '.join(f'{k}={v}' for k, v in vars(opt).items()))



def init_seeds(seed=0):
    """
    åˆå§‹åŒ–éšæœºæ•°ç”Ÿæˆå™¨ï¼ˆRNGï¼‰ç§å­ã€‚

    è¯¥å‡½æ•°è®¾ç½® Pythonã€NumPy å’Œ PyTorch çš„éšæœºç§å­ï¼Œä»¥ç¡®ä¿å®éªŒçš„å¯é‡å¤æ€§ã€‚
    ä½¿ç”¨ç§å­ 0 æ—¶ï¼Œcudnn çš„è®¾ç½®æ›´æ…¢ä½†æ›´å¯é‡å¤ï¼›å…¶ä»–ç§å­åˆ™æ›´å¿«ä½†å¯é‡å¤æ€§è¾ƒå·®ã€‚

    Arguments:
        seed (int): è¦è®¾ç½®çš„éšæœºç§å­ï¼Œé»˜è®¤ä¸º 0ã€‚

    å‚è€ƒæ–‡çŒ®:
        - PyTorch éšæœºæ€§è¯´æ˜: https://pytorch.org/docs/stable/notes/randomness.html
    """

    import torch.backends.cudnn as cudnn
    import random
    import numpy as np

    # è®¾ç½®éšæœºç§å­
    random.seed(seed)  # Python å†…ç½®éšæœºæ¨¡å—
    np.random.seed(seed)  # NumPy éšæœºæ•°ç”Ÿæˆ
    torch.manual_seed(seed)  # PyTorch éšæœºæ•°ç”Ÿæˆ

    # è®¾ç½® cuDNN çš„éšæœºæ€§å‚æ•°
    # seed ä¸º 0 æ—¶ï¼Œcudnn è®¾ç½®ä¸ºæ…¢ä½†å¯é‡å¤ï¼›å¦åˆ™å¿«é€Ÿä½†å¯é‡å¤æ€§è¾ƒå·®
    cudnn.benchmark, cudnn.deterministic = (False, True) if seed == 0 else (True, False)



def get_latest_run(search_dir='.'):
    # è¿”å›æŒ‡å®šç›®å½•ä¸­æœ€è¿‘çš„ 'last.pt' æ–‡ä»¶çš„è·¯å¾„ï¼Œç”¨äºä»æœ€è¿‘çš„æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ
    # åœ¨ search_dir ç›®å½•ä¸‹é€’å½’æŸ¥æ‰¾æ‰€æœ‰ç¬¦åˆ 'last*.pt' æ¨¡å¼çš„æ–‡ä»¶
    last_list = glob.glob(f'{search_dir}/**/last*.pt', recursive=True)
    # å¦‚æœæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶ï¼Œè¿”å›æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶è·¯å¾„ï¼›è‹¥æ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    return max(last_list, key=os.path.getctime) if last_list else ''


def user_config_dir(dir='Ultralytics', env_var='YOLOV5_CONFIG_DIR'):
    """
    è¿”å›ç”¨æˆ·é…ç½®ç›®å½•çš„è·¯å¾„ã€‚å¦‚æœå­˜åœ¨ç¯å¢ƒå˜é‡ï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ã€‚å¦‚æœéœ€è¦ï¼Œåˆ›å»ºè¯¥ç›®å½•ã€‚

    Arguments:
        dir (str): è¦åˆ›å»ºçš„å­ç›®å½•åç§°ï¼Œé»˜è®¤ä¸º 'Ultralytics'ã€‚
        env_var (str): æŒ‡å®šçš„ç¯å¢ƒå˜é‡åç§°ï¼Œé»˜è®¤ä¸º 'YOLOV5_CONFIG_DIR'ã€‚

    Returns:
        Path: ç”¨æˆ·é…ç½®ç›®å½•çš„è·¯å¾„ã€‚
    """

    # è·å–ç¯å¢ƒå˜é‡çš„å€¼
    env = os.getenv(env_var)

    if env:
        # å¦‚æœç¯å¢ƒå˜é‡å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨è¯¥è·¯å¾„
        path = Path(env)
    else:
        # å®šä¹‰ä¸åŒæ“ä½œç³»ç»Ÿä¸‹çš„é…ç½®ç›®å½•
        cfg = {'Windows': 'AppData/Roaming', 'Linux': '.config', 'Darwin': 'Library/Application Support'}  # 3ä¸ªæ“ä½œç³»ç»Ÿç›®å½•
        # è·å–å½“å‰ç”¨æˆ·çš„ä¸»ç›®å½•ï¼Œå¹¶æ‹¼æ¥æ“ä½œç³»ç»Ÿç‰¹å®šçš„é…ç½®ç›®å½•
        path = Path.home() / cfg.get(platform.system(), '')  # æ ¹æ®æ“ä½œç³»ç»Ÿè¿”å›ç›¸åº”çš„é…ç½®ç›®å½•

        # å¦‚æœè¯¥è·¯å¾„ä¸å¯å†™ï¼Œåˆ™ä½¿ç”¨ '/tmp' ç›®å½•
        path = (path if is_writeable(path) else Path('/tmp')) / dir  # GCP å’Œ AWS lambda çš„ä¿®å¤ï¼Œåªæœ‰ /tmp å¯å†™

    # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœéœ€è¦ï¼‰
    path.mkdir(exist_ok=True)

    return path


def is_writeable(dir, test=False):
    """
    æ£€æŸ¥ç›®å½•æ˜¯å¦å…·æœ‰å†™å…¥æƒé™ã€‚å¦‚æœ test=Trueï¼Œå°†å°è¯•ä»¥å†™æƒé™æ‰“å¼€ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œæµ‹è¯•ã€‚

    Arguments:
        dir (str or Path): è¦æ£€æŸ¥çš„ç›®å½•è·¯å¾„ã€‚
        test (bool): æ˜¯å¦è¿›è¡Œå†™æƒé™æµ‹è¯•ï¼Œé»˜è®¤ä¸º Falseã€‚

    Returns:
        bool: å¦‚æœç›®å½•å¯å†™ï¼Œè¿”å› Trueï¼›å¦åˆ™è¿”å› Falseã€‚
    """

    if test:  # å¦‚æœéœ€è¦æµ‹è¯•å†™æƒé™
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶çš„è·¯å¾„
        file = Path(dir) / 'tmp.txt'
        try:
            # å°è¯•ä»¥å†™æƒé™æ‰“å¼€æ–‡ä»¶
            with open(file, 'w'):
                pass  # åˆ›å»ºæ–‡ä»¶å¹¶ç«‹å³å…³é—­
            file.unlink()  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            return True  # å¦‚æœæˆåŠŸï¼Œè¿”å› True
        except IOError:
            return False  # å¦‚æœå‡ºç° IOErrorï¼Œè¿”å› False
    else:  # ä¸è¿›è¡Œæµ‹è¯•ï¼Œç›´æ¥æ£€æŸ¥è¯»å–æƒé™
        # ä½¿ç”¨ os.access æ£€æŸ¥ç›®å½•çš„è¯»å–æƒé™
        return os.access(dir, os.R_OK)  # å¯èƒ½åœ¨ Windows ä¸Šæœ‰é—®é¢˜


def is_docker():
    """
    æ£€æŸ¥å½“å‰ç¯å¢ƒæ˜¯å¦ä¸º Docker å®¹å™¨ã€‚

    Returns:
        bool: å¦‚æœå½“å‰ç¯å¢ƒæ˜¯ Docker å®¹å™¨ï¼Œè¿”å› Trueï¼›å¦åˆ™è¿”å› Falseã€‚
    """

    # æ£€æŸ¥ '/workspace' ç›®å½•æ˜¯å¦å­˜åœ¨
    return Path('/workspace').exists()  # æˆ–è€…æ£€æŸ¥ '/.dockerenv' ç›®å½•æ˜¯å¦å­˜åœ¨


def is_colab():
    """
    æ£€æŸ¥å½“å‰ç¯å¢ƒæ˜¯å¦ä¸º Google Colab å®ä¾‹ã€‚

    Returns:
        bool: å¦‚æœå½“å‰ç¯å¢ƒæ˜¯ Google Colabï¼Œè¿”å› Trueï¼›å¦åˆ™è¿”å› Falseã€‚
    """

    try:
        import google.colab  # å°è¯•å¯¼å…¥ google.colab æ¨¡å—
        return True  # æˆåŠŸå¯¼å…¥ï¼Œè¯´æ˜æ˜¯åœ¨ Colab ç¯å¢ƒä¸­
    except ImportError:
        return False  # å¯¼å…¥å¤±è´¥ï¼Œè¯´æ˜ä¸æ˜¯ Colab ç¯å¢ƒ


def is_pip():
    """
    æ£€æŸ¥å½“å‰æ–‡ä»¶æ˜¯å¦åœ¨ pip åŒ…ä¸­ã€‚

    Returns:
        bool: å¦‚æœå½“å‰æ–‡ä»¶ä½äº pip å®‰è£…çš„ site-packages ç›®å½•ä¸­ï¼Œè¿”å› Trueï¼›å¦åˆ™è¿”å› Falseã€‚
    """

    # æ£€æŸ¥å½“å‰æ–‡ä»¶è·¯å¾„çš„å„ä¸ªéƒ¨åˆ†æ˜¯å¦åŒ…å« 'site-packages'
    return 'site-packages' in Path(__file__).resolve().parts


def is_ascii(s=''):
    """
    æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ç”±æ‰€æœ‰ ASCII å­—ç¬¦ç»„æˆï¼ˆä¸åŒ…å« UTF å­—ç¬¦ï¼‰ã€‚

    Args:
        s (str): è¦æ£€æŸ¥çš„å­—ç¬¦ä¸²ï¼Œé»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²ã€‚

    Returns:
        bool: å¦‚æœå­—ç¬¦ä¸²å®Œå…¨ç”± ASCII å­—ç¬¦ç»„æˆï¼Œè¿”å› Trueï¼›å¦åˆ™è¿”å› Falseã€‚
    """

    # å°†è¾“å…¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œä»¥å¤„ç†åˆ—è¡¨ã€å…ƒç»„ã€None ç­‰ç±»å‹
    s = str(s)

    # ç¼–ç ä¸º ASCII å¹¶è§£ç ï¼Œå¿½ç•¥é ASCII å­—ç¬¦ï¼Œç„¶åæ¯”è¾ƒé•¿åº¦
    return len(s.encode().decode('ascii', 'ignore')) == len(s)


def is_chinese(s='äººå·¥æ™ºèƒ½'):
    """
    æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦åŒ…å«ä»»ä½•ä¸­æ–‡å­—ç¬¦ã€‚

    Args:
        s (str): è¦æ£€æŸ¥çš„å­—ç¬¦ä¸²ï¼Œé»˜è®¤ä¸º 'äººå·¥æ™ºèƒ½'ã€‚

    Returns:
        bool: å¦‚æœå­—ç¬¦ä¸²ä¸­åŒ…å«ä¸­æ–‡å­—ç¬¦ï¼Œåˆ™è¿”å› Trueï¼›å¦åˆ™è¿”å› Falseã€‚
    """
    return re.search('[\u4e00-\u9fff]', s) is not None



def emojis(str=''):
    """
    è¿”å›å¹³å°ç›¸å…³çš„ã€å®‰å…¨çš„è¡¨æƒ…ç¬¦å·å­—ç¬¦ä¸²ç‰ˆæœ¬ã€‚

    Args:
        str (str): è¦å¤„ç†çš„å­—ç¬¦ä¸²ï¼Œé»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²ã€‚

    Returns:
        str: å¤„ç†åçš„å­—ç¬¦ä¸²ï¼Œé€‚åˆåœ¨ä¸åŒå¹³å°ä¸Šä½¿ç”¨ã€‚
    """
    return str.encode().decode('ascii', 'ignore') if platform.system() == 'Windows' else str



def file_size(path):
    """
    è¿”å›æ–‡ä»¶æˆ–ç›®å½•çš„å¤§å°ï¼ˆä»¥ MB ä¸ºå•ä½ï¼‰ã€‚

    Args:
        path (str): æ–‡ä»¶æˆ–ç›®å½•çš„è·¯å¾„ã€‚

    Returns:
        float: æ–‡ä»¶æˆ–ç›®å½•çš„å¤§å°ï¼ˆMBï¼‰ã€‚å¦‚æœè·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ™è¿”å› 0.0ã€‚
    """
    path = Path(path)
    if path.is_file():
        return path.stat().st_size / 1E6  # è¿”å›æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
    elif path.is_dir():
        return sum(f.stat().st_size for f in path.glob('**/*') if f.is_file()) / 1E6  # è¿”å›ç›®å½•å¤§å°ï¼ˆMBï¼‰
    else:
        return 0.0  # å¦‚æœè·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ™è¿”å› 0.0



def check_online():
    """
    æ£€æŸ¥äº’è”ç½‘è¿æ¥çŠ¶æ€ã€‚

    Returns:
        bool: å¦‚æœèƒ½å¤ŸæˆåŠŸè¿æ¥åˆ°äº’è”ç½‘ï¼Œè¿”å› Trueï¼›å¦åˆ™è¿”å› Falseã€‚
    """
    import socket
    try:
        # å°è¯•è¿æ¥åˆ° 1.1.1.1ï¼ˆCloudflare DNSï¼‰ä¸Šçš„ 443 ç«¯å£ï¼Œä»¥æ£€æŸ¥ä¸»æœºå¯è®¿é—®æ€§
        socket.create_connection(("1.1.1.1", 443), 5)
        return True  # å¦‚æœè¿æ¥æˆåŠŸï¼Œè¿”å› True
    except OSError:
        return False  # å¦‚æœå‡ºç° OSErrorï¼Œè¿”å› False



@try_except
def check_git_status():
    # æ£€æŸ¥Gitä»“åº“çŠ¶æ€ï¼Œå¦‚æœä»£ç ä¸æ˜¯æœ€æ–°ç‰ˆæœ¬ï¼Œå»ºè®®ç”¨æˆ·æ‰§è¡Œ`git pull`æ›´æ–°
    msg = ', for updates see https://github.com/ultralytics/yolov5'  # æç¤ºæ¶ˆæ¯é“¾æ¥
    print(colorstr('github: '), end='')  # æ‰“å°å¸¦é¢œè‰²çš„â€œgithubâ€æ ‡ç­¾ï¼Œä¾¿äºåœ¨æ§åˆ¶å°è¯†åˆ«è¾“å‡ºæ¥æº

    # ç¡®ä¿å½“å‰ç›®å½•æ˜¯Gitä»“åº“ï¼Œå¦åˆ™è·³è¿‡æ£€æŸ¥
    assert Path('.git').exists(), 'skipping check (not a git repository)' + msg
    # å¦‚æœåœ¨Dockerå®¹å™¨ä¸­è¿è¡Œï¼Œè·³è¿‡æ£€æŸ¥
    assert not is_docker(), 'skipping check (Docker image)' + msg
    # æ£€æŸ¥æ˜¯å¦åœ¨çº¿ï¼Œç¦»çº¿åˆ™è·³è¿‡æ£€æŸ¥
    assert check_online(), 'skipping check (offline)' + msg

    # è·å–å½“å‰ä»“åº“çš„è¿œç¨‹URLå’Œåˆ†æ”¯çŠ¶æ€
    cmd = 'git fetch && git config --get remote.origin.url'  # åŒæ­¥è¿œç¨‹ä»“åº“å¹¶è·å–URL
    url = check_output(cmd, shell=True, timeout=5).decode().strip().rstrip('.git')  # è·å–ä»“åº“URLå¹¶å»æ‰â€œ.gitâ€åç¼€
    branch = check_output('git rev-parse --abbrev-ref HEAD', shell=True).decode().strip()  # è·å–å½“å‰åˆ†æ”¯åç§°
    n = int(check_output(f'git rev-list {branch}..origin/master --count', shell=True))  # è·å–æœ¬åœ°åˆ†æ”¯ç›¸å¯¹è¿œç¨‹ä¸»åˆ†æ”¯çš„è½åæäº¤æ•°

    # å¦‚æœè½åæäº¤æ•°å¤§äº0ï¼Œæç¤ºæ›´æ–°å‘½ä»¤ï¼Œå¦åˆ™ç¡®è®¤ä»“åº“å·²æœ€æ–°
    if n > 0:
        s = f"âš ï¸ YOLOv5 is out of date by {n} commit{'s' * (n > 1)}. Use `git pull` or `git clone {url}` to update."
    else:
        s = f'up to date with {url} âœ…'
    print(emojis(s))  # ä½¿ç”¨emojié£æ ¼æ‰“å°æ¶ˆæ¯ï¼Œæ”¯æŒåœ¨ä¸åŒæ§åˆ¶å°ä¸­å®‰å…¨æ˜¾ç¤º



def check_python(minimum='3.6.2'):
    # æ£€æŸ¥å½“å‰çš„Pythonç‰ˆæœ¬æ˜¯å¦ç¬¦åˆè¦æ±‚çš„æœ€ä½ç‰ˆæœ¬
    check_version(platform.python_version(), minimum, name='Python ')


def check_version(current='0.0.0', minimum='0.0.0', name='version ', pinned=False):
    # æ£€æŸ¥å½“å‰ç‰ˆæœ¬ä¸è¦æ±‚çš„ç‰ˆæœ¬
    current, minimum = (pkg.parse_version(x) for x in (current, minimum))  # è§£æå½“å‰å’Œæœ€ä½ç‰ˆæœ¬
    result = (current == minimum) if pinned else (current >= minimum)  # æ¯”è¾ƒå½“å‰ç‰ˆæœ¬ä¸æœ€ä½ç‰ˆæœ¬
    assert result, f'{name}{minimum} required by YOLOv5, but {name}{current} is currently installed'
    # å¦‚æœå½“å‰ç‰ˆæœ¬ä¸ç¬¦åˆè¦æ±‚ï¼ŒæŠ›å‡ºå¼‚å¸¸å¹¶ç»™å‡ºæç¤º



@try_except
def check_requirements(requirements=ROOT / 'requirements.txt', exclude=(), install=True):
    # æ£€æŸ¥å·²å®‰è£…çš„ä¾èµ–æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼ˆæ”¯æŒä¼ å…¥ *.txt æ–‡ä»¶æˆ–åŒ…åˆ—è¡¨ï¼‰
    prefix = colorstr('red', 'bold', 'requirements:')  # è®¾ç½®å‰ç¼€ï¼Œä¾¿äºé”™è¯¯è¾“å‡ºæ—¶è¯†åˆ«
    check_python()  # æ£€æŸ¥ Python ç‰ˆæœ¬æ˜¯å¦ç¬¦åˆè¦æ±‚

    # æ£€æŸ¥ requirements å‚æ•°æ˜¯å¦ä¸ºè·¯å¾„ï¼ˆå³ requirements.txt æ–‡ä»¶ï¼‰
    if isinstance(requirements, (str, Path)):
        file = Path(requirements)  # å°†è·¯å¾„å­—ç¬¦ä¸²è½¬ä¸º Path å¯¹è±¡
        assert file.exists(), f"{prefix} {file.resolve()} not found, check failed."  # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        # ä»æ–‡ä»¶ä¸­è¯»å–å¹¶è§£æåŒ…çš„åç§°å’Œç‰ˆæœ¬è¦æ±‚ï¼Œå¹¶æ’é™¤ exclude åˆ—è¡¨ä¸­çš„åŒ…
        requirements = [f'{x.name}{x.specifier}' for x in pkg.parse_requirements(file.open()) if x.name not in exclude]
    else:
        # è‹¥ requirements æ˜¯åˆ—è¡¨æˆ–å…ƒç»„ï¼Œåˆ™ç›´æ¥æ’é™¤ exclude ä¸­çš„åŒ…
        requirements = [x for x in requirements if x not in exclude]

    n = 0  # è®°å½•è‡ªåŠ¨æ›´æ–°çš„åŒ…æ•°é‡
    for r in requirements:
        try:
            pkg.require(r)  # å°è¯•å¯¼å…¥å’Œæ£€æŸ¥åŒ…æ˜¯å¦ç¬¦åˆç‰ˆæœ¬è¦æ±‚
        except Exception as e:  # å¦‚æœæœªæ‰¾åˆ°åŒ…æˆ–ç‰ˆæœ¬å†²çªåˆ™æ•è·å¼‚å¸¸
            s = f"{prefix} {r} not found and is required by YOLOv5"  # æ˜¾ç¤ºç¼ºå°‘çš„åŒ…ä¿¡æ¯
            if install:  # è‹¥å…è®¸è‡ªåŠ¨å®‰è£…
                print(f"{s}, attempting auto-update...")
                try:
                    # æ£€æŸ¥æ˜¯å¦åœ¨çº¿ï¼Œè‹¥åœ¨çº¿åˆ™è‡ªåŠ¨å®‰è£…
                    assert check_online(), f"'pip install {r}' skipped (offline)"
                    print(check_output(f"pip install '{r}'", shell=True).decode())  # å®‰è£…ç¼ºå¤±çš„åŒ…
                    n += 1
                except Exception as e:
                    print(f'{prefix} {e}')  # æ‰“å°å®‰è£…å¤±è´¥çš„é”™è¯¯ä¿¡æ¯
            else:
                print(f'{s}. Please install and rerun your command.')  # æç¤ºç”¨æˆ·æ‰‹åŠ¨å®‰è£…

    # å¦‚æœæ›´æ–°äº†åŒ…ï¼Œæç¤ºç”¨æˆ·é‡å¯æˆ–é‡æ–°è¿è¡Œå‘½ä»¤ä»¥åº”ç”¨æ›´æ–°
    if n:
        source = file.resolve() if 'file' in locals() else requirements  # æ›´æ–°æºä¿¡æ¯ï¼ˆæ–‡ä»¶æˆ–åˆ—è¡¨ï¼‰
        s = f"{prefix} {n} package{'s' * (n > 1)} updated per {source}\n" \
            f"{prefix} âš ï¸ {colorstr('bold', 'Restart runtime or rerun command for updates to take effect')}\n"
        print(emojis(s))  # ä½¿ç”¨ emoji æ‰“å°å¸¦é¢œè‰²çš„æç¤ºä¿¡æ¯


def check_img_size(imgsz, s=32, floor=0):
    # Verify image size is a multiple of stride s in each dimension
    # éªŒè¯å›¾åƒå°ºå¯¸åœ¨æ¯ä¸ªç»´åº¦ä¸Šæ˜¯å¦ä¸ºæ­¥å¹… s çš„å€æ•°
    if isinstance(imgsz, int):  # å¦‚æœ img_size æ˜¯æ•´æ•°ï¼Œä¾‹å¦‚ img_size=640
        new_size = max(make_divisible(imgsz, int(s)), floor)  # å°†å›¾åƒå°ºå¯¸è°ƒæ•´ä¸º s çš„å€æ•°ï¼Œå¹¶ä¸å°äº floor
    else:  # å¦‚æœ img_size æ˜¯åˆ—è¡¨ï¼Œä¾‹å¦‚ img_size=[640, 480]
        new_size = [max(make_divisible(x, int(s)), floor) for x in imgsz]  # å¯¹æ¯ä¸ªç»´åº¦è¿›è¡Œç›¸åŒçš„å¤„ç†
    # å¦‚æœè°ƒæ•´åçš„å°ºå¯¸ä¸åŸå§‹å°ºå¯¸ä¸ä¸€è‡´
    if new_size != imgsz:
        print(f'WARNING: --img-size {imgsz} must be multiple of max stride {s}, updating to {new_size}')
        # è¾“å‡ºè­¦å‘Šï¼Œè¡¨æ˜åŸå§‹å°ºå¯¸å¿…é¡»æ˜¯æœ€å¤§æ­¥å¹… s çš„å€æ•°ï¼Œå¹¶æ˜¾ç¤ºæ›´æ–°åçš„å°ºå¯¸
    return new_size  # è¿”å›ç»è¿‡éªŒè¯å’Œè°ƒæ•´çš„å›¾åƒå°ºå¯¸



def check_imshow():
    # Check if environment supports image displays
    try:
        # æ£€æŸ¥å½“å‰ç¯å¢ƒæ˜¯å¦ä¸º Dockerï¼Œå¦‚æœæ˜¯ï¼Œåˆ™ cv2.imshow() ä¸æ”¯æŒ
        assert not is_docker(), 'cv2.imshow() is disabled in Docker environments'
        # æ£€æŸ¥å½“å‰ç¯å¢ƒæ˜¯å¦ä¸º Google Colabï¼Œå¦‚æœæ˜¯ï¼Œåˆ™ cv2.imshow() ä¸æ”¯æŒ
        assert not is_colab(), 'cv2.imshow() is disabled in Google Colab environments'
        # æµ‹è¯•æ˜¾ç¤ºä¸€å¹…ç©ºç™½å›¾åƒï¼Œç¡®ä¿ cv2.imshow() å¯ç”¨
        cv2.imshow('test', np.zeros((1, 1, 3)))  # åˆ›å»ºä¸€ä¸ª 1x1 çš„é»‘è‰²å›¾åƒå¹¶æ˜¾ç¤º
        cv2.waitKey(1)  # ç­‰å¾… 1 æ¯«ç§’ï¼Œä»¥ä¾¿å›¾åƒå¯ä»¥æ˜¾ç¤º
        cv2.destroyAllWindows()  # å…³é—­æ‰€æœ‰ OpenCV çª—å£
        cv2.waitKey(1)  # å†æ¬¡ç­‰å¾… 1 æ¯«ç§’ï¼Œä»¥ç¡®ä¿çª—å£å…³é—­
        return True  # å¦‚æœæ²¡æœ‰å¼‚å¸¸ï¼Œè¿”å› Trueï¼Œè¡¨ç¤ºæ”¯æŒå›¾åƒæ˜¾ç¤º
    except Exception as e:
        # æ•è·å¼‚å¸¸å¹¶è¾“å‡ºè­¦å‘Šï¼ŒæŒ‡æ˜ä¸æ”¯æŒå›¾åƒæ˜¾ç¤º
        print(f'WARNING: Environment does not support cv2.imshow() or PIL Image.show() image displays\n{e}')
        return False  # è¿”å› Falseï¼Œè¡¨ç¤ºä¸æ”¯æŒå›¾åƒæ˜¾ç¤º


def check_suffix(file='yolov5s.pt', suffix=('.pt',), msg=''):
    # Check file(s) for acceptable suffixes
    # æ£€æŸ¥æ–‡ä»¶ï¼ˆæˆ–æ–‡ä»¶åˆ—è¡¨ï¼‰æ˜¯å¦å…·æœ‰å¯æ¥å—çš„åç¼€
    if file and suffix:  # ç¡®ä¿æ–‡ä»¶å’Œåç¼€ä¸ä¸ºç©º
        if isinstance(suffix, str):  # å¦‚æœåç¼€æ˜¯å­—ç¬¦ä¸²ç±»å‹
            suffix = [suffix]  # å°†å…¶è½¬æ¢ä¸ºåˆ—è¡¨å½¢å¼ï¼Œä»¥ä¾¿åç»­å¤„ç†
        # éå†è¾“å…¥çš„æ–‡ä»¶ï¼ˆæ”¯æŒå•ä¸ªæ–‡ä»¶æˆ–æ–‡ä»¶åˆ—è¡¨ï¼‰
        for f in file if isinstance(file, (list, tuple)) else [file]:
            # æ£€æŸ¥æ–‡ä»¶çš„åç¼€æ˜¯å¦åœ¨æ¥å—çš„åç¼€åˆ—è¡¨ä¸­
            assert Path(f).suffix.lower() in suffix, f"{msg}{f} acceptable suffix is {suffix}"
            # å¦‚æœåç¼€ä¸åœ¨æ¥å—çš„åç¼€åˆ—è¡¨ä¸­ï¼ŒæŠ›å‡º AssertionErrorï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯

def check_yaml(file, suffix=('.yaml', '.yml')):
    # æ£€æŸ¥æŒ‡å®šçš„æ–‡ä»¶æ˜¯å¦ä¸º YAML æ–‡ä»¶ï¼Œå¿…è¦æ—¶è¿›è¡Œä¸‹è½½ï¼Œå¹¶è¿”å›æ–‡ä»¶è·¯å¾„
    # ä¼ é€’ file å’Œåç¼€ suffix åˆ° check_file å‡½æ•°ï¼ŒéªŒè¯æ–‡ä»¶åç¼€æ˜¯å¦ä¸º '.yaml' æˆ– '.yml'
    return check_file(file, suffix)



def check_file(file, suffix=''):
    # æ£€æŸ¥æ–‡ä»¶è·¯å¾„çš„æœ‰æ•ˆæ€§ï¼Œè‹¥æ–‡ä»¶ä¸å­˜åœ¨åˆ™ä¸‹è½½æˆ–æœç´¢ï¼Œæœ€ç»ˆè¿”å›æ–‡ä»¶è·¯å¾„
    check_suffix(file, suffix)  # å¯é€‰ï¼šæ£€æŸ¥æ–‡ä»¶åç¼€æ˜¯å¦ç¬¦åˆæŒ‡å®šæ ¼å¼
    file = str(file)  # ç¡®ä¿ file æ˜¯å­—ç¬¦ä¸²æ ¼å¼
    if Path(file).is_file() or file == '':  # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨æˆ–è·¯å¾„ä¸ºç©º
        return file
    elif file.startswith(('http:/', 'https:/')):  # è‹¥è·¯å¾„ä¸ºURLï¼Œä¸‹è½½æ–‡ä»¶
        url = str(Path(file)).replace(':/', '://')  # ä¿®å¤Pathå¯¹è±¡æ ¼å¼åŒ–URLæ—¶çš„':'é—®é¢˜
        file = Path(urllib.parse.unquote(file).split('?')[0]).name  # è·å–æ–‡ä»¶åå¹¶ç§»é™¤URLä¸­çš„å‚æ•°
        print(f'Downloading {url} to {file}...')
        torch.hub.download_url_to_file(url, file)  # ä½¿ç”¨PyTorchå·¥å…·ä¸‹è½½æ–‡ä»¶
        # ç¡®ä¿æ–‡ä»¶æˆåŠŸä¸‹è½½ä¸”éç©º
        assert Path(file).exists() and Path(file).stat().st_size > 0, f'File download failed: {url}'
        return file
    else:  # è‹¥è·¯å¾„ä¸æ˜¯URLä¸”æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¼€å§‹æœç´¢æ–‡ä»¶
        files = []
        for d in 'data', 'models', 'utils':  # åœ¨ç‰¹å®šçš„ç›®å½•ä¸­æœç´¢æ–‡ä»¶
            files.extend(glob.glob(str(ROOT / d / '**' / file), recursive=True))  # é€’å½’æœç´¢åŒ¹é…çš„æ–‡ä»¶
        assert len(files), f'File not found: {file}'  # å¦‚æœæ‰¾ä¸åˆ°æ–‡ä»¶åˆ™æŠ¥é”™
        assert len(files) == 1, f"Multiple files match '{file}', specify exact path: {files}"  # è‹¥æ‰¾åˆ°å¤šä¸ªæ–‡ä»¶åˆ™æŠ¥é”™
        return files[0]  # è¿”å›å”¯ä¸€åŒ¹é…çš„æ–‡ä»¶è·¯å¾„



def check_dataset(data, autodownload=True):
    """
    æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨ã€‚å¦‚æœæ•°æ®é›†åœ¨æœ¬åœ°æœªæ‰¾åˆ°ï¼Œåˆ™ä¸‹è½½å¹¶/æˆ–è§£å‹æ•°æ®é›†ã€‚
    ä½¿ç”¨ç¤ºä¾‹: https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128_with_yaml.zip

    å‚æ•°:
        data (str or Path): æ•°æ®é›†çš„è·¯å¾„æˆ– URLï¼Œæ”¯æŒ .zip æ–‡ä»¶ã€‚
        autodownload (bool): å¦‚æœä¸º Trueï¼Œå°è¯•è‡ªåŠ¨ä¸‹è½½æ•°æ®é›†ã€‚

    è¿”å›:
        dict: åŒ…å«æ•°æ®é›†è·¯å¾„åŠå…¶ä»–ä¿¡æ¯çš„å­—å…¸ã€‚
    """

    # ä¸‹è½½ï¼ˆå¯é€‰ï¼‰
    extract_dir = ''
    if isinstance(data, (str, Path)) and str(data).endswith('.zip'):
        # å¦‚æœ data æ˜¯ä¸€ä¸ª zip æ–‡ä»¶è·¯å¾„ï¼Œåˆ™ä¸‹è½½å¹¶è§£å‹
        download(data, dir='../datasets', unzip=True, delete=False, curl=False, threads=1)
        # è·å–è§£å‹åçš„ yaml æ–‡ä»¶è·¯å¾„
        data = next((Path('../datasets') / Path(data).stem).rglob('*.yaml'))
        extract_dir, autodownload = data.parent, False  # æ›´æ–°æå–ç›®å½•å¹¶ç¦ç”¨è‡ªåŠ¨ä¸‹è½½

    # è¯»å– yaml æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    if isinstance(data, (str, Path)):
        with open(data, errors='ignore') as f:
            data = yaml.safe_load(f)  # å°† yaml æ–‡ä»¶åŠ è½½ä¸ºå­—å…¸

    # è§£æ yaml å†…å®¹
    path = extract_dir or Path(data.get('path') or '')  # å¯é€‰çš„ 'path' é»˜è®¤è®¾ç½®ä¸ºå½“å‰ç›®å½•
    for k in 'train', 'val', 'test':
        if data.get(k):  # å¦‚æœå­˜åœ¨ç›¸åº”è·¯å¾„
            # é¢„pend path
            data[k] = str(path / data[k]) if isinstance(data[k], str) else [str(path / x) for x in data[k]]

    assert 'nc' in data, "æ•°æ®é›†ç¼ºå°‘ 'nc' é”®ã€‚"  # æ£€æŸ¥ 'nc' é”®æ˜¯å¦å­˜åœ¨
    if 'names' not in data:
        # å¦‚æœ 'names' é”®ç¼ºå¤±ï¼Œåˆ™ä¸ºæ¯ä¸ªç±»åˆ†é…é»˜è®¤åç§°
        data['names'] = [f'class{i}' for i in range(data['nc'])]
    train, val, test, s = [data.get(x) for x in ('train', 'val', 'test', 'download')]

    # æ£€æŸ¥éªŒè¯é›†è·¯å¾„æ˜¯å¦å­˜åœ¨
    if val:
        val = [Path(x).resolve() for x in (val if isinstance(val, list) else [val])]  # è·å–éªŒè¯é›†è·¯å¾„
        if not all(x.exists() for x in val):  # æ£€æŸ¥æ‰€æœ‰è·¯å¾„æ˜¯å¦å­˜åœ¨
            print('\nWARNING: æ•°æ®é›†æœªæ‰¾åˆ°ï¼Œç¼ºå¤±è·¯å¾„: %s' % [str(x) for x in val if not x.exists()])
            if s and autodownload:  # å¦‚æœå­˜åœ¨ä¸‹è½½è„šæœ¬å¹¶å…è®¸è‡ªåŠ¨ä¸‹è½½
                root = path.parent if 'path' in data else '..'  # è§£å‹ç›®å½• i.e. '../'
                if s.startswith('http') and s.endswith('.zip'):  # URL
                    f = Path(s).name  # æ–‡ä»¶å
                    print(f'æ­£åœ¨ä¸‹è½½ {s} åˆ° {f}...')
                    torch.hub.download_url_to_file(s, f)  # ä¸‹è½½æ–‡ä»¶
                    Path(root).mkdir(parents=True, exist_ok=True)  # åˆ›å»ºæ ¹ç›®å½•
                    ZipFile(f).extractall(path=root)  # è§£å‹æ–‡ä»¶
                    Path(f).unlink()  # åˆ é™¤ zip æ–‡ä»¶
                    r = None  # ä¸‹è½½æˆåŠŸæ ‡å¿—
                elif s.startswith('bash '):  # bash è„šæœ¬
                    print(f'æ­£åœ¨è¿è¡Œ {s} ...')
                    r = os.system(s)  # æ‰§è¡Œ bash è„šæœ¬
                else:  # python è„šæœ¬
                    r = exec(s, {'yaml': data})  # æ‰§è¡Œ python è„šæœ¬
                print(f"æ•°æ®é›†è‡ªåŠ¨ä¸‹è½½ {f'success, saved to {root}' if r in (0, None) else 'failure'}\n")
            else:
                raise Exception('æ•°æ®é›†æœªæ‰¾åˆ°ã€‚')  # æŠ›å‡ºå¼‚å¸¸

    return data  # è¿”å›åŒ…å«æ•°æ®é›†ä¿¡æ¯çš„å­—å…¸


def url2file(url):
    # å°†URLè½¬æ¢ä¸ºæ–‡ä»¶åï¼Œä¾‹å¦‚å°† https://url.com/file.txt?auth è½¬æ¢ä¸º file.txt
    url = str(Path(url)).replace(':/', '://')  # å°†è·¯å¾„ä¸­çš„ :/ æ›¿æ¢ä¸º ://ï¼Œä»¥é¿å…Pathlibçš„å¤„ç†é—®é¢˜
    file = Path(urllib.parse.unquote(url)).name.split('?')[0]  # å°†URLè§£ç ï¼Œè·å–æ–‡ä»¶åï¼Œå¹¶å»æ‰æŸ¥è¯¢å‚æ•°éƒ¨åˆ†
    return file  # è¿”å›æå–çš„æ–‡ä»¶å



def download(url, dir='.', unzip=True, delete=True, curl=False, threads=1):
    # å¤šçº¿ç¨‹æ–‡ä»¶ä¸‹è½½å’Œè§£å‹å‡½æ•°ï¼Œç”¨äº data.yaml ä¸­çš„è‡ªåŠ¨ä¸‹è½½
    def download_one(url, dir):
        # ä¸‹è½½å•ä¸ªæ–‡ä»¶
        f = dir / Path(url).name  # è·å–æ–‡ä»¶å
        if Path(url).is_file():  # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨äºå½“å‰è·¯å¾„
            Path(url).rename(f)  # å°†æ–‡ä»¶ç§»åŠ¨åˆ°æŒ‡å®šç›®å½•
        elif not f.exists():
            print(f'Downloading {url} to {f}...')  # å¼€å§‹ä¸‹è½½
            if curl:
                # ä½¿ç”¨ curl è¿›è¡Œä¸‹è½½ï¼Œæ”¯æŒé‡è¯•å’Œæ–­ç‚¹ç»­ä¼ 
                os.system(f"curl -L '{url}' -o '{f}' --retry 9 -C -")
            else:
                # ä½¿ç”¨ torch ä¸‹è½½æ–‡ä»¶
                torch.hub.download_url_to_file(url, f, progress=True)
        # å¦‚æœéœ€è¦è§£å‹å¹¶ä¸”æ–‡ä»¶æ˜¯å‹ç¼©æ ¼å¼
        if unzip and f.suffix in ('.zip', '.gz'):
            print(f'Unzipping {f}...')
            if f.suffix == '.zip':
                ZipFile(f).extractall(path=dir)  # è§£å‹ zip æ–‡ä»¶
            elif f.suffix == '.gz':
                os.system(f'tar xfz {f} --directory {f.parent}')  # è§£å‹ gz æ–‡ä»¶
            if delete:
                f.unlink()  # åˆ é™¤å‹ç¼©æ–‡ä»¶

    dir = Path(dir)
    dir.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºç›®å½•
    if threads > 1:
        pool = ThreadPool(threads)
        # ä½¿ç”¨å¤šçº¿ç¨‹ä¸‹è½½
        pool.imap(lambda x: download_one(*x), zip(url, repeat(dir)))
        pool.close()
        pool.join()
    else:
        # å¦‚æœæ²¡æœ‰ä½¿ç”¨å¤šçº¿ç¨‹ï¼Œé€ä¸ªä¸‹è½½
        for u in [url] if isinstance(url, (str, Path)) else url:
            download_one(u, dir)



def make_divisible(x, divisor):
    # Returns x evenly divisible by divisor
    # è¿”å› x è¢« divisor æ•´é™¤çš„æœ€å°å€¼
    return math.ceil(x / divisor) * divisor  # å…ˆè®¡ç®— x é™¤ä»¥ divisor çš„ç»“æœï¼Œå†å‘ä¸Šå–æ•´ï¼Œæœ€åä¹˜ä»¥ divisor å¾—åˆ°å¯æ•´é™¤çš„å€¼



def clean_str(s):
    # æ¸…ç†å­—ç¬¦ä¸²ï¼Œé€šè¿‡å°†ç‰¹æ®Šå­—ç¬¦æ›¿æ¢ä¸ºä¸‹åˆ’çº¿ _
    return re.sub(pattern="[|@#!Â¡Â·$â‚¬%&()=?Â¿^*;:,Â¨Â´><+]", repl="_", string=s)



def one_cycle(y1=0.0, y2=1.0, steps=100):
    """
    åˆ›å»ºä¸€ä¸ªä» y1 åˆ° y2 çš„æ­£å¼¦æ³¢å½¢å­¦ä¹ ç‡è°ƒåº¦å‡½æ•°ã€‚

    å‚æ•°:
    y1 (float): å­¦ä¹ ç‡è°ƒåº¦çš„èµ·å§‹å€¼ï¼Œé»˜è®¤ä¸º 0.0ã€‚
    y2 (float): å­¦ä¹ ç‡è°ƒåº¦çš„ç»“æŸå€¼ï¼Œé»˜è®¤ä¸º 1.0ã€‚
    steps (int): å­¦ä¹ ç‡å˜åŒ–çš„æ­¥éª¤æ•°é‡ï¼Œé»˜è®¤ä¸º 100ã€‚

    è¿”å›:
    function: ä¸€ä¸ªæ¥å—å•ä¸ªå‚æ•° x çš„ lambda å‡½æ•°ï¼Œè¯¥å‚æ•°è¡¨ç¤ºå½“å‰æ­¥éª¤ï¼Œè¿”å›åœ¨è¯¥æ­¥éª¤çš„å­¦ä¹ ç‡å€¼ã€‚

    å‚è€ƒæ–‡çŒ®:
    https://arxiv.org/pdf/1812.01187.pdf
    """
    # è¿”å›ä¸€ä¸ª lambda å‡½æ•°ï¼Œè¯¥å‡½æ•°è®¡ç®—ä» y1 åˆ° y2 çš„æ­£å¼¦æ³¢å½¢è°ƒåº¦
    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1


def colorstr(*input):
    # ç»™å­—ç¬¦ä¸²ç€è‰²ï¼Œå‚è€ƒï¼šhttps://en.wikipedia.org/wiki/ANSI_escape_codeï¼Œä¾‹å¦‚ï¼šcolorstr('blue', 'hello world')
    *args, string = input if len(input) > 1 else ('blue', 'bold', input[0])  # é¢œè‰²å‚æ•°ï¼Œå­—ç¬¦ä¸²
    colors = {
        'black': '\033[30m',  # åŸºæœ¬é¢œè‰²
        'red': '\033[31m',
        'green': '\033[32m',
        'yellow': '\033[33m',
        'blue': '\033[34m',
        'magenta': '\033[35m',
        'cyan': '\033[36m',
        'white': '\033[37m',
        'bright_black': '\033[90m',  # æ˜äº®é¢œè‰²
        'bright_red': '\033[91m',
        'bright_green': '\033[92m',
        'bright_yellow': '\033[93m',
        'bright_blue': '\033[94m',
        'bright_magenta': '\033[95m',
        'bright_cyan': '\033[96m',
        'bright_white': '\033[97m',
        'end': '\033[0m',  # å…¶ä»–
        'bold': '\033[1m',
        'underline': '\033[4m'
    }
    return ''.join(colors[x] for x in args) + f'{string}' + colors['end']



def labels_to_class_weights(labels, nc=80):
    # ä»è®­ç»ƒæ ‡ç­¾è·å–ç±»åˆ«æƒé‡ï¼ˆé€†é¢‘ç‡ï¼‰
    if labels[0] is None:  # å¦‚æœæ²¡æœ‰åŠ è½½æ ‡ç­¾
        return torch.Tensor()

    labels = np.concatenate(labels, 0)  # labels.shape = (866643, 5) å¯¹äº COCO æ•°æ®é›†
    classes = labels[:, 0].astype(np.int)  # labels = [class xywh]
    weights = np.bincount(classes, minlength=nc)  # æ¯ä¸ªç±»åˆ«çš„å‡ºç°æ¬¡æ•°

    # åœ¨å‰é¢æ·»åŠ ç½‘æ ¼ç‚¹è®¡æ•°ï¼ˆç”¨äº uCE è®­ç»ƒï¼‰
    # gpi = ((320 / 32 * np.array([1, 2, 4])) ** 2 * 3).sum()  # æ¯å¼ å›¾ç‰‡çš„ç½‘æ ¼ç‚¹
    # weights = np.hstack([gpi * len(labels) - weights.sum() * 9, weights * 9]) ** 0.5  # åœ¨å¼€å§‹æ—¶æ·»åŠ ç½‘æ ¼ç‚¹

    weights[weights == 0] = 1  # å°†ç©ºçš„ç±»åˆ«æƒé‡æ›¿æ¢ä¸º 1
    weights = 1 / weights  # æ¯ä¸ªç±»åˆ«çš„ç›®æ ‡æ•°é‡
    weights /= weights.sum()  # å½’ä¸€åŒ–
    return torch.from_numpy(weights)



def labels_to_image_weights(labels, nc=80, class_weights=np.ones(80)):
    # æ ¹æ®ç±»æƒé‡å’Œå›¾åƒå†…å®¹ç”Ÿæˆå›¾åƒæƒé‡
    # labels: æ¯ä¸ªå›¾åƒçš„æ ‡ç­¾ï¼Œå½¢çŠ¶ä¸º(n, 5)ï¼Œå…¶ä¸­ n æ˜¯ç›®æ ‡æ•°é‡ï¼Œ5 åŒ…å« [class, x, y, w, h]
    # nc: ç±»çš„æ•°é‡ï¼Œé»˜è®¤ä¸º80
    # class_weights: æ¯ä¸ªç±»çš„æƒé‡ï¼Œé»˜è®¤ä¸ºå…¨1çš„æ•°ç»„

    # è®¡ç®—æ¯ä¸ªå›¾åƒä¸­æ¯ä¸ªç±»çš„ç›®æ ‡æ•°é‡
    class_counts = np.array([np.bincount(x[:, 0].astype(np.int), minlength=nc) for x in labels])

    # è®¡ç®—æ¯ä¸ªå›¾åƒçš„æƒé‡ï¼Œæƒé‡ä¸ºç±»æƒé‡ä¸ç›®æ ‡æ•°é‡çš„ä¹˜ç§¯çš„æ€»å’Œ
    image_weights = (class_weights.reshape(1, nc) * class_counts).sum(1)

    # è¿”å›æ¯ä¸ªå›¾åƒçš„æƒé‡
    return image_weights


def coco80_to_coco91_class():  # å°†COCOæ•°æ®é›†çš„80ç±»ç´¢å¼•è½¬æ¢ä¸º91ç±»ç´¢å¼•
    # å‚è€ƒé“¾æ¥ï¼šhttps://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/
    # a = np.loadtxt('data/coco.names', dtype='str', delimiter='\n')  # åŠ è½½COCOç±»å
    # b = np.loadtxt('data/coco_paper.names', dtype='str', delimiter='\n')  # åŠ è½½è®ºæ–‡ä¸­ç±»å
    # x1 = [list(a[i] == b).index(True) + 1 for i in range(80)]  # ä»darknetåˆ°COCOçš„æ˜ å°„
    # x2 = [list(b[i] == a).index(True) if any(b[i] == a) else None for i in range(91)]  # ä»COCOåˆ°darknetçš„æ˜ å°„

    # ç›´æ¥å®šä¹‰ä»80ç±»åˆ°91ç±»çš„ç´¢å¼•æ˜ å°„
    x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34,
         35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,
         64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90]
    return x  # è¿”å›è½¬æ¢åçš„ç´¢å¼•åˆ—è¡¨


def xyxy2xywh(x):
    # å°† nx4 çš„è¾¹ç•Œæ¡†ä» [x1, y1, x2, y2] è½¬æ¢ä¸º [x, y, w, h]ï¼Œå…¶ä¸­ xy1=å·¦ä¸Šè§’ï¼Œxy2=å³ä¸‹è§’
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)  # æ ¹æ®è¾“å…¥ç±»å‹åˆ›å»ºå‰¯æœ¬
    y[:, 0] = (x[:, 0] + x[:, 2]) / 2  # è®¡ç®— x ä¸­å¿ƒ
    y[:, 1] = (x[:, 1] + x[:, 3]) / 2  # è®¡ç®— y ä¸­å¿ƒ
    y[:, 2] = x[:, 2] - x[:, 0]  # è®¡ç®—å®½åº¦
    y[:, 3] = x[:, 3] - x[:, 1]  # è®¡ç®—é«˜åº¦
    return y



def xywh2xyxy(x):
    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2]
    # å°†nx4æ ¼å¼çš„æ¡†ä»[x, y, w, h]è½¬æ¢ä¸º[x1, y1, x2, y2]æ ¼å¼
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)  # åˆ›å»ºè¾“å…¥xçš„å‰¯æœ¬
    y[:, 0] = x[:, 0] - x[:, 2] / 2  # è®¡ç®—å·¦ä¸Šè§’çš„xåæ ‡
    y[:, 1] = x[:, 1] - x[:, 3] / 2  # è®¡ç®—å·¦ä¸Šè§’çš„yåæ ‡
    y[:, 2] = x[:, 0] + x[:, 2] / 2  # è®¡ç®—å³ä¸‹è§’çš„xåæ ‡
    y[:, 3] = x[:, 1] + x[:, 3] / 2  # è®¡ç®—å³ä¸‹è§’çš„yåæ ‡
    return y  # è¿”å›è½¬æ¢åçš„åæ ‡



def xywhn2xyxy(x, w=640, h=640, padw=0, padh=0):
    # å°† nx4 çš„è¾¹ç•Œæ¡†ä» [x, y, w, h]ï¼ˆå½’ä¸€åŒ–ï¼‰è½¬æ¢ä¸º [x1, y1, x2, y2]ï¼Œå…¶ä¸­ xy1=å·¦ä¸Šè§’ï¼Œxy2=å³ä¸‹è§’
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)  # æ ¹æ®è¾“å…¥ç±»å‹åˆ›å»ºå‰¯æœ¬
    y[:, 0] = w * (x[:, 0] - x[:, 2] / 2) + padw  # è®¡ç®—å·¦ä¸Šè§’ x
    y[:, 1] = h * (x[:, 1] - x[:, 3] / 2) + padh  # è®¡ç®—å·¦ä¸Šè§’ y
    y[:, 2] = w * (x[:, 0] + x[:, 2] / 2) + padw  # è®¡ç®—å³ä¸‹è§’ x
    y[:, 3] = h * (x[:, 1] + x[:, 3] / 2) + padh  # è®¡ç®—å³ä¸‹è§’ y
    return y



def xyxy2xywhn(x, w=640, h=640, clip=False, eps=0.0):
    # å°† nx4 çš„è¾¹ç•Œæ¡†ä» [x1, y1, x2, y2] è½¬æ¢ä¸º [x, y, w, h]ï¼ˆå½’ä¸€åŒ–ï¼‰ï¼Œå…¶ä¸­ xy1=å·¦ä¸Šè§’ï¼Œxy2=å³ä¸‹è§’
    if clip:
        clip_coords(x, (h - eps, w - eps))  # è­¦å‘Šï¼šå°±åœ°è£å‰ª
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)  # æ ¹æ®è¾“å…¥ç±»å‹åˆ›å»ºå‰¯æœ¬
    y[:, 0] = ((x[:, 0] + x[:, 2]) / 2) / w  # è®¡ç®—ä¸­å¿ƒ xï¼ˆå½’ä¸€åŒ–ï¼‰
    y[:, 1] = ((x[:, 1] + x[:, 3]) / 2) / h  # è®¡ç®—ä¸­å¿ƒ yï¼ˆå½’ä¸€åŒ–ï¼‰
    y[:, 2] = (x[:, 2] - x[:, 0]) / w  # è®¡ç®—å®½åº¦ï¼ˆå½’ä¸€åŒ–ï¼‰
    y[:, 3] = (x[:, 3] - x[:, 1]) / h  # è®¡ç®—é«˜åº¦ï¼ˆå½’ä¸€åŒ–ï¼‰
    return y



def xyn2xy(x, w=640, h=640, padw=0, padh=0):
    # å°†å½’ä¸€åŒ–çš„åæ ‡è½¬æ¢ä¸ºåƒç´ åæ ‡ï¼Œå½¢çŠ¶ä¸º (n, 2)
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)  # æ ¹æ®è¾“å…¥ç±»å‹åˆ›å»ºå‰¯æœ¬
    y[:, 0] = w * x[:, 0] + padw  # è®¡ç®—å·¦ä¸Šè§’ xï¼ˆåƒç´ ï¼‰
    y[:, 1] = h * x[:, 1] + padh  # è®¡ç®—å·¦ä¸Šè§’ yï¼ˆåƒç´ ï¼‰
    return y



def segment2box(segment, width=640, height=640):
    # å°†ä¸€ä¸ªåˆ†æ®µæ ‡ç­¾è½¬æ¢ä¸ºä¸€ä¸ªæ¡†æ ‡ç­¾ï¼Œåº”ç”¨å›¾åƒå†…çº¦æŸï¼Œå³å°† (xy1, xy2, ...) è½¬æ¢ä¸º (xyxy)
    x, y = segment.T  # æå–åˆ†æ®µçš„ x å’Œ y åæ ‡
    inside = (x >= 0) & (y >= 0) & (x <= width) & (y <= height)  # æ£€æŸ¥åæ ‡æ˜¯å¦åœ¨å›¾åƒå†…
    x, y = x[inside], y[inside]  # ä»…ä¿ç•™åœ¨å›¾åƒå†…çš„åæ ‡
    return np.array([x.min(), y.min(), x.max(), y.max()]) if any(x) else np.zeros((1, 4))  # è¿”å›æ¡†åæ ‡ (xyxy) æˆ–é›¶æ•°ç»„



def segments2boxes(segments):
    # å°†åˆ†æ®µæ ‡ç­¾è½¬æ¢ä¸ºæ¡†æ ‡ç­¾ï¼Œå³å°† (cls, xy1, xy2, ...) è½¬æ¢ä¸º (cls, xywh)
    boxes = []
    for s in segments:
        x, y = s.T  # æå–åˆ†æ®µçš„ x å’Œ y åæ ‡
        boxes.append([x.min(), y.min(), x.max(), y.max()])  # è®¡ç®—æ¡†çš„æœ€å°å’Œæœ€å¤§ xã€y åæ ‡ï¼Œå½¢æˆ (xyxy) æ ¼å¼
    return xyxy2xywh(np.array(boxes))  # å°†æ¡†è½¬æ¢ä¸º (cls, xywh) æ ¼å¼



def resample_segments(segments, n=1000):
    # å¯¹ (n,2) åˆ†æ®µè¿›è¡Œä¸Šé‡‡æ ·
    for i, s in enumerate(segments):
        x = np.linspace(0, len(s) - 1, n)  # åˆ›å»ºå‡åŒ€åˆ†å¸ƒçš„ n ä¸ªç‚¹
        xp = np.arange(len(s))  # åŸå§‹ç´¢å¼•
        segments[i] = np.concatenate([np.interp(x, xp, s[:, i]) for i in range(2)]).reshape(2, -1).T  # é€šè¿‡æ’å€¼ç”Ÿæˆæ–°çš„åˆ†æ®µåæ ‡
    return segments  # è¿”å›ä¸Šé‡‡æ ·åçš„åˆ†æ®µ



def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):
    # Rescale coords (xyxy) from img1_shape to img0_shape
    if ratio_pad is None:  # å¦‚æœæ²¡æœ‰æä¾›æ¯”ä¾‹å¡«å……ï¼Œåˆ™ä»img0_shapeè®¡ç®—
        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # è®¡ç®—ç¼©æ”¾æ¯”
        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # è®¡ç®—å¡«å……
    else:
        gain = ratio_pad[0][0]  # ä»ç»™å®šçš„æ¯”ä¾‹å¡«å……ä¸­è·å–ç¼©æ”¾æ¯”
        pad = ratio_pad[1]  # è·å–å¡«å……å€¼

    coords[:, [0, 2]] -= pad[0]  # å¯¹xåæ ‡è¿›è¡Œå¡«å……è°ƒæ•´
    coords[:, [1, 3]] -= pad[1]  # å¯¹yåæ ‡è¿›è¡Œå¡«å……è°ƒæ•´
    coords[:, :4] /= gain  # æ ¹æ®ç¼©æ”¾æ¯”è°ƒæ•´åæ ‡
    clip_coords(coords, img0_shape)  # å°†åæ ‡é™åˆ¶åœ¨åŸå§‹å›¾åƒè¾¹ç•Œå†…
    return coords  # è¿”å›è°ƒæ•´åçš„åæ ‡



def clip_coords(boxes, shape):
    # å°†è¾¹ç•Œæ¡† (xyxy) é™åˆ¶åœ¨å›¾åƒå½¢çŠ¶å†… (é«˜åº¦, å®½åº¦)
    if isinstance(boxes, torch.Tensor):  # å¦‚æœæ˜¯ PyTorch å¼ é‡ï¼ˆå•ç‹¬å¤„ç†é€Ÿåº¦æ›´å¿«ï¼‰
        boxes[:, 0].clamp_(0, shape[1])  # é™åˆ¶ x1
        boxes[:, 1].clamp_(0, shape[0])  # é™åˆ¶ y1
        boxes[:, 2].clamp_(0, shape[1])  # é™åˆ¶ x2
        boxes[:, 3].clamp_(0, shape[0])  # é™åˆ¶ y2
    else:  # å¦‚æœæ˜¯ numpy æ•°ç»„ï¼ˆæ‰¹é‡å¤„ç†é€Ÿåº¦æ›´å¿«ï¼‰
        boxes[:, [0, 2]] = boxes[:, [0, 2]].clip(0, shape[1])  # é™åˆ¶ x1 å’Œ x2
        boxes[:, [1, 3]] = boxes[:, [1, 3]].clip(0, shape[0])  # é™åˆ¶ y1 å’Œ y2



def non_max_suppression(prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False, multi_label=False,
                        labels=(), max_det=300):
    """å¯¹æ¨ç†ç»“æœæ‰§è¡Œéæå¤§å€¼æŠ‘åˆ¶ï¼ˆNMSï¼‰

    å‚æ•°ï¼š
        prediction: æ¨¡å‹çš„é¢„æµ‹ç»“æœ
        conf_thres: ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œä½äºæ­¤é˜ˆå€¼çš„æ£€æµ‹å°†è¢«è¿‡æ»¤
        iou_thres: IOUï¼ˆIntersection over Unionï¼‰é˜ˆå€¼ï¼Œç”¨äºåˆ¤æ–­é‡å æ¡†çš„åˆå¹¶
        classes: è¦è€ƒè™‘çš„ç±»åˆ«åˆ—è¡¨
        agnostic: å¦‚æœä¸ºTrueï¼Œåˆ™ç±»åˆ«ä¹‹é—´ä¸è¿›è¡ŒåŒºåˆ†
        multi_label: å¦‚æœä¸ºTrueï¼Œåˆ™æ¯ä¸ªæ¡†å¯ä»¥å…·æœ‰å¤šä¸ªæ ‡ç­¾
        labels: çœŸå®æ ‡ç­¾ï¼Œç”¨äºè‡ªæ ‡æ³¨
        max_det: æ¯å¼ å›¾åƒæœ€å¤§æ£€æµ‹æ¡†æ•°

    è¿”å›ï¼š
         æ¯å¼ å›¾åƒçš„æ£€æµ‹ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªæ£€æµ‹ç»“æœä¸º(n, 6)çš„å¼ é‡ [xyxy, conf, cls]
    """

    # nc: ç±»åˆ«æ•°
    nc = prediction.shape[2] - 5  # é¢„æµ‹ç»“æœä¸­çš„ç±»åˆ«æ•°
    xc = prediction[..., 4] > conf_thres  # ç¬¦åˆç½®ä¿¡åº¦é˜ˆå€¼çš„å€™é€‰æ¡†

    # æ£€æŸ¥é˜ˆå€¼æœ‰æ•ˆæ€§
    assert 0 <= conf_thres <= 1, f'Invalid Confidence threshold {conf_thres}, valid values are between 0.0 and 1.0'
    assert 0 <= iou_thres <= 1, f'Invalid IoU {iou_thres}, valid values are between 0.0 and 1.0'

    # è®¾ç½®å‚æ•°
    min_wh, max_wh = 2, 4096  # (åƒç´ ) æœ€å°å’Œæœ€å¤§æ¡†å®½é«˜
    max_nms = 30000  # ä¼ å…¥ torchvision.ops.nms() çš„æœ€å¤§æ¡†æ•°
    time_limit = 10.0  # è¶…è¿‡æ­¤æ—¶é—´åé€€å‡º
    redundant = True  # æ˜¯å¦éœ€è¦å†—ä½™æ£€æµ‹
    multi_label &= nc > 1  # å¦‚æœç±»åˆ«æ•°å¤§äº1ï¼Œå¯ç”¨å¤šæ ‡ç­¾ï¼ˆå¢åŠ å¤„ç†æ—¶é—´ï¼‰
    merge = False  # æ˜¯å¦ä½¿ç”¨åˆå¹¶ NMS

    t = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
    output = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]  # åˆå§‹åŒ–è¾“å‡º
    for xi, x in enumerate(prediction):  # éå†æ¯å¼ å›¾åƒçš„é¢„æµ‹ç»“æœ
        # åº”ç”¨çº¦æŸæ¡ä»¶
        x = x[xc[xi]]  # ä»…ä¿ç•™ç¬¦åˆç½®ä¿¡åº¦é˜ˆå€¼çš„æ¡†

        # å¦‚æœå­˜åœ¨çœŸå®æ ‡ç­¾ï¼Œåˆ™å°†å…¶åˆå¹¶åˆ°é¢„æµ‹ç»“æœä¸­
        if labels and len(labels[xi]):
            l = labels[xi]  # çœŸå®æ ‡ç­¾
            v = torch.zeros((len(l), nc + 5), device=x.device)  # åˆå§‹åŒ–ä¸çœŸå®æ ‡ç­¾ç›¸åŒå½¢çŠ¶çš„å¼ é‡
            v[:, :4] = l[:, 1:5]  # æå–çœŸå®æ¡†çš„åæ ‡
            v[:, 4] = 1.0  # ç½®ä¿¡åº¦è®¾ä¸º1.0
            v[range(len(l)), l[:, 0].long() + 5] = 1.0  # è®¾ç½®ç±»åˆ«
            x = torch.cat((x, v), 0)  # åˆå¹¶é¢„æµ‹æ¡†å’ŒçœŸå®æ¡†

        # å¦‚æœæ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ¡†ï¼Œåˆ™å¤„ç†ä¸‹ä¸€ä¸ªå›¾åƒ
        if not x.shape[0]:
            continue

        # è®¡ç®—ç½®ä¿¡åº¦
        x[:, 5:] *= x[:, 4:5]  # ç½®ä¿¡åº¦ = ç›®æ ‡ç½®ä¿¡åº¦ * ç±»åˆ«ç½®ä¿¡åº¦

        # å°†æ¡†ä» (ä¸­å¿ƒx, ä¸­å¿ƒy, å®½, é«˜) è½¬æ¢ä¸º (x1, y1, x2, y2)
        box = xywh2xyxy(x[:, :4])

        # åˆ›å»ºæ£€æµ‹çŸ©é˜µ nx6 (xyxy, conf, cls)
        if multi_label:
            i, j = (x[:, 5:] > conf_thres).nonzero(as_tuple=False).T  # ç¡®å®šå“ªäº›æ¡†ç¬¦åˆå¤šæ ‡ç­¾æ¡ä»¶
            x = torch.cat((box[i], x[i, j + 5, None], j[:, None].float()), 1)  # åˆå¹¶æ¡†ä¿¡æ¯
        else:  # ä»…ä¿ç•™æœ€ä½³ç±»åˆ«
            conf, j = x[:, 5:].max(1, keepdim=True)  # æ‰¾åˆ°ç½®ä¿¡åº¦æœ€é«˜çš„ç±»åˆ«
            x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]  # åˆå¹¶æ¡†å’Œç½®ä¿¡åº¦

        # æ ¹æ®ç±»åˆ«è¿‡æ»¤æ¡†
        if classes is not None:
            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]  # ä»…ä¿ç•™æŒ‡å®šç±»åˆ«çš„æ¡†

        # æ£€æŸ¥æ¡†çš„æ•°é‡
        n = x.shape[0]  # å½“å‰æ¡†çš„æ•°é‡
        if not n:  # å¦‚æœæ²¡æœ‰æ¡†
            continue
        elif n > max_nms:  # å¦‚æœæ¡†çš„æ•°é‡è¶…è¿‡æœ€å¤§é™åˆ¶
            x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # æŒ‰ç½®ä¿¡åº¦æ’åºå¹¶ä¿ç•™å‰ max_nms ä¸ªæ¡†

        # æ‰¹é‡å¤„ç† NMS
        c = x[:, 5:6] * (0 if agnostic else max_wh)  # å¤„ç†ç±»ä¿¡æ¯
        boxes, scores = x[:, :4] + c, x[:, 4]  # æ·»åŠ ç±»åˆ«åç§»ï¼Œè·å–æ¡†å’Œç½®ä¿¡åº¦
        i = torchvision.ops.nms(boxes, scores, iou_thres)  # æ‰§è¡Œ NMS
        if i.shape[0] > max_det:  # å¦‚æœæ£€æµ‹åˆ°çš„æ¡†æ•°é‡è¶…è¿‡é™åˆ¶
            i = i[:max_det]  # ä»…ä¿ç•™æœ€å¤§æ£€æµ‹æ•°

        # å¯é€‰çš„åˆå¹¶ NMSï¼ˆä½¿ç”¨åŠ æƒå‡å€¼åˆå¹¶æ¡†ï¼‰
        if merge and (1 < n < 3E3):  # å¦‚æœéœ€è¦åˆå¹¶ä¸”æ£€æµ‹æ¡†æ•°é‡åˆç†
            iou = box_iou(boxes[i], boxes) > iou_thres  # è®¡ç®— IOU çŸ©é˜µ
            weights = iou * scores[None]  # è®¡ç®—æ¡†çš„æƒé‡
            x[i, :4] = torch.mm(weights, x[:, :4]).float() / weights.sum(1, keepdim=True)  # æ›´æ–°æ¡†ä¸ºåŠ æƒå‡å€¼
            if redundant:
                i = i[iou.sum(1) > 1]  # å¦‚æœéœ€è¦å†—ä½™ï¼Œä¿ç•™ç¬¦åˆæ¡ä»¶çš„æ¡†

        output[xi] = x[i]  # å°†ç»“æœå­˜å‚¨åˆ°è¾“å‡ºä¸­
        if (time.time() - t) > time_limit:  # å¦‚æœè¶…å‡ºæ—¶é—´é™åˆ¶
            print(f'WARNING: NMS time limit {time_limit}s exceeded')
            break  # è¶…æ—¶é€€å‡º

    return output  # è¿”å›æ¯å¼ å›¾åƒçš„æ£€æµ‹ç»“æœ


def strip_optimizer(f='best.pt', s=''):  # from utils.general import *; strip_optimizer()
    # ä»æ–‡ä»¶ 'f' ä¸­å»é™¤ä¼˜åŒ–å™¨ä¿¡æ¯ï¼Œä»¥å®Œæˆè®­ç»ƒï¼Œå¹¶å¯é€‰æ‹©æ€§åœ°ä¿å­˜ä¸º 's'
    x = torch.load(f, map_location=torch.device('cpu'))  # åŠ è½½æ¨¡å‹æ–‡ä»¶
    if x.get('ema'):  # å¦‚æœå­˜åœ¨ EMA (Exponential Moving Average) æ¨¡å‹
        x['model'] = x['ema']  # ç”¨ EMA æ¨¡å‹æ›¿æ¢åŸæ¨¡å‹
    for k in 'optimizer', 'training_results', 'wandb_id', 'ema', 'updates':  # ç§»é™¤æŒ‡å®šçš„é”®
        x[k] = None
    x['epoch'] = -1  # è®¾ç½®ä¸º-1ï¼Œè¡¨ç¤ºè®­ç»ƒå·²ç»“æŸ
    x['model'].half()  # å°†æ¨¡å‹è½¬æ¢ä¸º FP16 ç²¾åº¦
    for p in x['model'].parameters():  # è®¾ç½®æ¨¡å‹å‚æ•°ä¸ºä¸éœ€è¦æ¢¯åº¦
        p.requires_grad = False
    torch.save(x, s or f)  # ä¿å­˜æ¨¡å‹ï¼Œä¼˜å…ˆä¿å­˜ä¸º 's'ï¼Œå¦åˆ™ä¿å­˜ä¸º 'f'
    mb = os.path.getsize(s or f) / 1E6  # è·å–æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
    print(f"Optimizer stripped from {f},{(' saved as %s,' % s) if s else ''} {mb:.1f}MB")  # æ‰“å°ä¿¡æ¯



def print_mutation(results, hyp, save_dir, bucket):
    # å®šä¹‰è¾“å‡ºæ–‡ä»¶è·¯å¾„
    evolve_csv = save_dir / 'evolve.csv'  # æ¼”åŒ–ç»“æœæ–‡ä»¶
    results_csv = save_dir / 'results.csv'  # ç»“æœæ–‡ä»¶ï¼ˆæœªä½¿ç”¨ï¼‰
    evolve_yaml = save_dir / 'hyp_evolve.yaml'  # è¶…å‚æ•°æ¼”åŒ– YAML æ–‡ä»¶

    # å®šä¹‰è¦è®°å½•çš„é”®ï¼ŒåŒ…æ‹¬è¯„ä¼°æŒ‡æ ‡å’Œè¶…å‚æ•°
    keys = ('metrics/precision', 'metrics/recall', 'metrics/mAP_0.5', 'metrics/mAP_0.5:0.95',
            'val/box_loss', 'val/obj_loss', 'val/cls_loss') + tuple(hyp.keys())  # [ç»“æœ + è¶…å‚æ•°]
    keys = tuple(x.strip() for x in keys)  # å»æ‰å¤šä½™çš„ç©ºæ ¼
    vals = results + tuple(hyp.values())  # ç»„åˆç»“æœå’Œè¶…å‚æ•°å€¼
    n = len(keys)  # é”®çš„æ•°é‡

    # å¯é€‰ï¼šä¸‹è½½ evolve.csv æ–‡ä»¶
    if bucket:
        url = f'gs://{bucket}/evolve.csv'  # äº‘å­˜å‚¨ä¸­çš„æ–‡ä»¶ URL
        # å¦‚æœäº‘ç«¯æ–‡ä»¶å¤§äºæœ¬åœ°æ–‡ä»¶ï¼Œåˆ™ä¸‹è½½
        if gsutil_getsize(url) > (os.path.getsize(evolve_csv) if os.path.exists(evolve_csv) else 0):
            os.system(f'gsutil cp {url} {save_dir}')  # ä¸‹è½½ evolve.csv

    # è®°å½•åˆ° evolve.csv æ–‡ä»¶
    # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™æ·»åŠ æ ‡é¢˜
    s = '' if evolve_csv.exists() else (('%20s,' * n % keys).rstrip(',') + '\n')  # æ·»åŠ è¡¨å¤´
    with open(evolve_csv, 'a') as f:
        f.write(s + ('%20.5g,' * n % vals).rstrip(',') + '\n')  # å†™å…¥æ•°æ®

    # æ‰“å°åˆ°å±å¹•
    print(colorstr('evolve: ') + ', '.join(f'{x.strip():>20s}' for x in keys))  # æ‰“å°é”®
    print(colorstr('evolve: ') + ', '.join(f'{x:20.5g}' for x in vals), end='\n\n\n')  # æ‰“å°å€¼

    # ä¿å­˜è¶…å‚æ•°æ¼”åŒ–ç»“æœä¸º YAML æ–‡ä»¶
    with open(evolve_yaml, 'w') as f:
        data = pd.read_csv(evolve_csv)  # è¯»å– evolve.csv
        data = data.rename(columns=lambda x: x.strip())  # å»æ‰åˆ—åçš„ç©ºæ ¼
        i = np.argmax(fitness(data.values[:, :7]))  # æ‰¾åˆ°æœ€ä½³ç»“æœçš„ç´¢å¼•
        # å†™å…¥æ–‡ä»¶å¤´å’Œæœ€ä½³ç»“æœä¿¡æ¯
        f.write('# YOLOv5 Hyperparameter Evolution Results\n' +
                f'# Best generation: {i}\n' +
                f'# Last generation: {len(data)}\n' +
                '# ' + ', '.join(f'{x.strip():>20s}' for x in keys[:7]) + '\n' +
                '# ' + ', '.join(f'{x:>20.5g}' for x in data.values[i, :7]) + '\n\n')
        yaml.safe_dump(hyp, f, sort_keys=False)  # ä¿å­˜è¶…å‚æ•°åˆ° YAML æ–‡ä»¶

    # å¯é€‰ï¼šä¸Šä¼  evolve.csv å’Œ YAML æ–‡ä»¶åˆ°äº‘å­˜å‚¨
    if bucket:
        os.system(f'gsutil cp {evolve_csv} {evolve_yaml} gs://{bucket}')  # ä¸Šä¼ 



def apply_classifier(x, model, img, im0):
    # å¯¹ YOLO è¾“å‡ºåº”ç”¨ç¬¬äºŒé˜¶æ®µåˆ†ç±»å™¨
    im0 = [im0] if isinstance(im0, np.ndarray) else im0  # å¦‚æœ im0 æ˜¯ ndarray ç±»å‹ï¼Œåˆ™å°†å…¶æ”¾å…¥åˆ—è¡¨ä¸­
    for i, d in enumerate(x):  # éå†æ¯ä¸ªå›¾åƒçš„æ£€æµ‹ç»“æœ
        if d is not None and len(d):
            d = d.clone()  # å…‹éš†æ£€æµ‹ç»“æœï¼Œä»¥å…ä¿®æ”¹åŸå§‹æ•°æ®

            # é‡å¡‘å’Œå¡«å……åˆ‡å‰²åŒºåŸŸ
            b = xyxy2xywh(d[:, :4])  # å°†æ£€æµ‹æ¡†åæ ‡ä» (x1, y1, x2, y2) è½¬æ¢ä¸º (x_center, y_center, width, height)
            b[:, 2:] = b[:, 2:].max(1)[0].unsqueeze(1)  # å°†çŸ©å½¢æ¡†è°ƒæ•´ä¸ºæ­£æ–¹å½¢
            b[:, 2:] = b[:, 2:] * 1.3 + 30  # åœ¨æ­£æ–¹å½¢çš„åŸºç¡€ä¸Šå¢åŠ å¡«å……ï¼Œ30ä¸ºå¡«å……çš„åƒç´ 
            d[:, :4] = xywh2xyxy(b).long()  # å°†æ­£æ–¹å½¢æ¡†è½¬æ¢å› (x1, y1, x2, y2) æ ¼å¼å¹¶è½¬ä¸ºæ•´å‹

            # å°†æ£€æµ‹æ¡†ä» img_size é‡æ–°ç¼©æ”¾åˆ° im0 å¤§å°
            scale_coords(img.shape[2:], d[:, :4], im0[i].shape)  # æ ¹æ®åŸå§‹å›¾åƒçš„å°ºå¯¸ç¼©æ”¾æ£€æµ‹æ¡†

            # è·å–ç±»åˆ«ä¿¡æ¯
            pred_cls1 = d[:, 5].long()  # æå–é¢„æµ‹çš„ç±»åˆ«
            ims = []  # ç”¨äºå­˜å‚¨å¤„ç†åçš„å›¾åƒ
            for j, a in enumerate(d):  # éå†æ¯ä¸ªæ£€æµ‹ç»“æœ
                cutout = im0[i][int(a[1]):int(a[3]), int(a[0]):int(a[2])]  # ä»åŸå›¾åƒä¸­è£å‰ªå‡ºæ£€æµ‹åŒºåŸŸ
                im = cv2.resize(cutout, (224, 224))  # å°†è£å‰ªåçš„å›¾åƒè°ƒæ•´ä¸º 224x224 å°ºå¯¸ (BGRæ ¼å¼)
                # cv2.imwrite('example%i.jpg' % j, cutout)  # ï¼ˆå¯é€‰ï¼‰ä¿å­˜è£å‰ªå›¾åƒ

                im = im[:, :, ::-1].transpose(2, 0, 1)  # BGR è½¬ RGBï¼Œå¹¶è°ƒæ•´ç»´åº¦ä¸º 3x224x224
                im = np.ascontiguousarray(im, dtype=np.float32)  # å°†æ•°æ®ç±»å‹è½¬æ¢ä¸º float32
                im /= 255.0  # å°†åƒç´ å€¼ä» 0-255 èŒƒå›´ç¼©æ”¾åˆ° 0.0-1.0
                ims.append(im)  # å°†å¤„ç†åçš„å›¾åƒæ·»åŠ åˆ°åˆ—è¡¨ä¸­

            pred_cls2 = model(torch.Tensor(ims).to(d.device)).argmax(1)  # ä½¿ç”¨åˆ†ç±»å™¨è¿›è¡Œé¢„æµ‹ï¼Œå¾—åˆ°ç±»åˆ«ç´¢å¼•
            x[i] = x[i][pred_cls1 == pred_cls2]  # ä¿ç•™ç±»åˆ«åŒ¹é…çš„æ£€æµ‹ç»“æœ

    return x  # è¿”å›ç»è¿‡åˆ†ç±»å™¨å¤„ç†åçš„æ£€æµ‹ç»“æœ


def save_one_box(xyxy, im, file='image.jpg', gain=1.02, pad=10, square=False, BGR=False, save=True):
    # å°†å›¾åƒè£å‰ªä¿å­˜ä¸º {file}ï¼Œè£å‰ªå¤§å°ä¸ºåŸå§‹å¤§å°çš„ {gain} å€ï¼Œå¹¶åŠ  {pad} åƒç´ çš„è¾¹è·ã€‚å¯é€‰æ‹©ä¿å­˜æˆ–è¿”å›è£å‰ªç»“æœ
    xyxy = torch.tensor(xyxy).view(-1, 4)  # å°†è¾“å…¥çš„åæ ‡è½¬æ¢ä¸ºå¼ é‡å¹¶è°ƒæ•´å½¢çŠ¶
    b = xyxy2xywh(xyxy)  # å°†åæ ‡ä» [x1, y1, x2, y2] è½¬æ¢ä¸º [x, y, w, h]

    if square:
        b[:, 2:] = b[:, 2:].max(1)[0].unsqueeze(1)  # å¦‚æœéœ€è¦ï¼Œå°†çŸ©å½¢è£å‰ªæ¡†è°ƒæ•´ä¸ºæ­£æ–¹å½¢

    b[:, 2:] = b[:, 2:] * gain + pad  # è°ƒæ•´è£å‰ªæ¡†çš„å®½é«˜ï¼Œä¹˜ä»¥å¢ç›Šå¹¶åŠ ä¸Šè¾¹è·
    xyxy = xywh2xyxy(b).long()  # å°†è°ƒæ•´åçš„å®½é«˜æ¡†è½¬æ¢å› [x1, y1, x2, y2] æ ¼å¼
    clip_coords(xyxy, im.shape)  # ç¡®ä¿è£å‰ªæ¡†ä¸è¶…å‡ºå›¾åƒè¾¹ç•Œ
    crop = im[int(xyxy[0, 1]):int(xyxy[0, 3]), int(xyxy[0, 0]):int(xyxy[0, 2]), ::(1 if BGR else -1)]
    # æ ¹æ®åæ ‡è£å‰ªå›¾åƒï¼Œå¹¶æ ¹æ® BGR æ ‡å¿—é€‰æ‹©é€šé“é¡ºåº

    if save:
        cv2.imwrite(str(increment_path(file, mkdir=True).with_suffix('.jpg')), crop)  # ä¿å­˜è£å‰ªå›¾åƒ

    return crop  # è¿”å›è£å‰ªåçš„å›¾åƒ


def increment_path(path, exist_ok=False, sep='', mkdir=False):
    # Increment file or directory path, i.e. runs/exp --> runs/exp{sep}2, runs/exp{sep}3, ... etc.
    # é€’å¢æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„ï¼Œä¾‹å¦‚ï¼šruns/exp --> runs/exp2, runs/exp3 ç­‰
    path = Path(path)  # å°†è·¯å¾„è½¬æ¢ä¸º Path å¯¹è±¡ï¼Œç¡®ä¿è·¨å¹³å°å…¼å®¹æ€§ï¼ˆä¸ä¾èµ–æ“ä½œç³»ç»Ÿï¼‰
    if path.exists() and not exist_ok:  # å¦‚æœè·¯å¾„å·²ç»å­˜åœ¨å¹¶ä¸” exist_ok ä¸º Falseï¼Œåˆ™å¼€å§‹é€’å¢è·¯å¾„å
        suffix = path.suffix  # è·å–æ–‡ä»¶çš„åç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
        path = path.with_suffix('')  # å»æ‰æ–‡ä»¶åç¼€ï¼Œä¾¿äºé€’å¢æ“ä½œ
        dirs = glob.glob(f"{path}{sep}*")  # æŸ¥æ‰¾ä¸å½“å‰è·¯å¾„ç›¸ä¼¼çš„æ‰€æœ‰è·¯å¾„
        matches = [re.search(rf"%s{sep}(\d+)" % path.stem, d) for d in dirs]  # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…è·¯å¾„ä¸­çš„æ•°å­—ï¼ˆé€’å¢éƒ¨åˆ†ï¼‰
        i = [int(m.groups()[0]) for m in matches if m]  # æå–è·¯å¾„ä¸­åŒ¹é…åˆ°çš„æ•°å­—ï¼ˆé€’å¢çš„æ•°å­—éƒ¨åˆ†ï¼‰
        n = max(i) + 1 if i else 2  # ç¡®å®šé€’å¢çš„æ•°å­—ï¼Œå¦‚æœä¹‹å‰æ²¡æœ‰ï¼Œåˆ™ä» 2 å¼€å§‹
        path = Path(f"{path}{sep}{n}{suffix}")  # ç”Ÿæˆé€’å¢åçš„æ–°è·¯å¾„ï¼Œä¿æŒåŸå§‹åç¼€
    dir = path if path.suffix == '' else path.parent  # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨å…¶çˆ¶ç›®å½•ï¼›å¦‚æœæ˜¯ç›®å½•ï¼Œç›´æ¥ä½¿ç”¨è¯¥ç›®å½•
    if not dir.exists() and mkdir:  # å¦‚æœç›®å½•ä¸å­˜åœ¨å¹¶ä¸” mkdir ä¸º Trueï¼Œåˆ™åˆ›å»ºç›®å½•
        dir.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºç›®å½•ï¼Œç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨ï¼ˆparents=Trueï¼‰
    return path  # è¿”å›é€’å¢åçš„è·¯å¾„

