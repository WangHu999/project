# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
"""
PyTorch utils
"""

import datetime
import logging
import math
import os
import platform
import subprocess
import time
from contextlib import contextmanager
from copy import deepcopy
from pathlib import Path

import torch
import torch.distributed as dist
import torch.nn as nn
import torch.nn.functional as F
import torchvision

try:
    import thop  # for FLOPs computation
except ImportError:
    thop = None

LOGGER = logging.getLogger(__name__)


@contextmanager
def torch_distributed_zero_first(local_rank: int):
    """
    è£…é¥°å™¨ï¼Œç”¨äºä½¿æ‰€æœ‰åˆ†å¸ƒå¼è®­ç»ƒçš„è¿›ç¨‹ç­‰å¾…æ¯ä¸ª local_master å®ŒæˆæŸäº›æ“ä½œã€‚
    """

    # å¦‚æœå½“å‰è¿›ç¨‹çš„ local_rank ä¸æ˜¯ -1 æˆ– 0
    if local_rank not in [-1, 0]:
        # åœ¨æŒ‡å®šçš„è®¾å¤‡ä¸ŠåŒæ­¥æ‰€æœ‰è¿›ç¨‹ï¼Œç¡®ä¿å®ƒä»¬åœ¨æ‰§è¡Œåç»­æ“ä½œä¹‹å‰ç­‰å¾…
        dist.barrier(device_ids=[local_rank])

    yield  # æš‚åœå‡½æ•°æ‰§è¡Œï¼Œç­‰å¾…åç»­ä»£ç æ‰§è¡Œ

    # å¦‚æœå½“å‰è¿›ç¨‹æ˜¯ local_masterï¼ˆlocal_rank ä¸º 0ï¼‰
    if local_rank == 0:
        # åŒæ­¥æœ¬åœ° master è¿›ç¨‹ï¼Œç¡®ä¿å…¶å®Œæˆåç»­æ“ä½œåï¼Œå…¶ä»–è¿›ç¨‹æ‰èƒ½ç»§ç»­æ‰§è¡Œ
        dist.barrier(device_ids=[0])



def date_modified(path=__file__):
    # return human-readable file modification date, i.e. '2021-3-26'
    t = datetime.datetime.fromtimestamp(Path(path).stat().st_mtime)
    return f'{t.year}-{t.month}-{t.day}'


def git_describe(path=Path(__file__).parent):  # path must be a directory
    # return human-readable git description, i.e. v5.0-5-g3e25f1e https://git-scm.com/docs/git-describe
    s = f'git -C {path} describe --tags --long --always'
    try:
        return subprocess.check_output(s, shell=True, stderr=subprocess.STDOUT).decode()[:-1]
    except subprocess.CalledProcessError as e:
        return ''  # not a git repository


def select_device(device='', batch_size=None):
    # é€‰æ‹©å¯ç”¨çš„è®¡ç®—è®¾å¤‡ï¼Œdevice å¯ä»¥æ˜¯ 'cpu'ã€'0'ï¼ˆè¡¨ç¤ºç¬¬ä¸€å— GPUï¼‰æˆ– '0,1,2,3'ï¼ˆè¡¨ç¤ºå¤šå— GPUï¼‰

    s = f'YOLOv5 ğŸš€ {git_describe() or date_modified()} torch {torch.__version__} '  # åˆ›å»ºå­—ç¬¦ä¸²ï¼ŒåŒ…å« YOLOv5 ç‰ˆæœ¬ã€git æè¿°æˆ–ä¿®æ”¹æ—¥æœŸä»¥åŠ PyTorch ç‰ˆæœ¬
    device = str(device).strip().lower().replace('cuda:', '')  # å°† device è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå¹¶æ ¼å¼åŒ–ä¸º '0' å½¢å¼ï¼Œå»æ‰ 'cuda:' å‰ç¼€
    cpu = device == 'cpu'  # æ£€æŸ¥æ˜¯å¦è¯·æ±‚ä½¿ç”¨ CPU
    if cpu:
        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # å¼ºåˆ¶è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œä½¿ torch.cuda.is_available() è¿”å› Falseï¼Œç¦ç”¨ GPU
    elif device:  # å¦‚æœè¯·æ±‚ä½¿ç”¨é CPU çš„è®¾å¤‡
        os.environ['CUDA_VISIBLE_DEVICES'] = device  # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œä»¥æŒ‡å®šå¯ç”¨çš„ CUDA è®¾å¤‡
        assert torch.cuda.is_available(), f'CUDA unavailable, invalid device {device} requested'  # æ£€æŸ¥ CUDA æ˜¯å¦å¯ç”¨ï¼Œå¦‚æœä¸å¯ç”¨åˆ™æŠ›å‡ºå¼‚å¸¸

    cuda = not cpu and torch.cuda.is_available()  # å¦‚æœä¸æ˜¯ CPU å¹¶ä¸” CUDA å¯ç”¨ï¼Œåˆ™ cuda ä¸º True
    if cuda:
        devices = device.split(',') if device else '0'  # å°†è®¾å¤‡å­—ç¬¦ä¸²åˆ†å‰²ä¸ºåˆ—è¡¨ï¼ˆä¾‹å¦‚ '0,1,2'ï¼‰ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™é»˜è®¤ä¸º '0'
        n = len(devices)  # è®¡ç®—è¯·æ±‚çš„è®¾å¤‡æ•°é‡
        if n > 1 and batch_size:  # å¦‚æœè¯·æ±‚äº†å¤šä¸ªè®¾å¤‡ä¸”æä¾›äº† batch_size
            assert batch_size % n == 0, f'batch-size {batch_size} not multiple of GPU count {n}'  # æ£€æŸ¥ batch_size æ˜¯å¦èƒ½è¢«è®¾å¤‡æ•°é‡æ•´é™¤

        space = ' ' * (len(s) + 1)  # è®¡ç®—éœ€è¦çš„ç©ºæ ¼ï¼Œç¡®ä¿è®¾å¤‡ä¿¡æ¯çš„å¯¹é½
        for i, d in enumerate(devices):  # éå†æ¯ä¸ªè®¾å¤‡
            p = torch.cuda.get_device_properties(i)  # è·å–è®¾å¤‡çš„å±æ€§ä¿¡æ¯
            s += f"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / 1024 ** 2}MB)\n"  # æ·»åŠ è®¾å¤‡åç§°å’Œæ€»å†…å­˜ä¿¡æ¯ï¼Œå•ä½ä¸º MB
    else:
        s += 'CPU\n'  # å¦‚æœæ²¡æœ‰ CUDA è®¾å¤‡å¯ç”¨ï¼Œåˆ™æ·»åŠ  CPU ä¿¡æ¯

    # è®°å½•è®¾å¤‡ä¿¡æ¯ï¼Œå¤„ç† Windows ç³»ç»Ÿä¸­çš„ emoji é—®é¢˜
    LOGGER.info(s.encode().decode('ascii', 'ignore') if platform.system() == 'Windows' else s)

    return torch.device('cuda:0' if cuda else 'cpu')  # è¿”å›é€‰æ‹©çš„è®¾å¤‡ï¼ˆCUDA è®¾å¤‡æˆ– CPUï¼‰


def time_sync():
    # PyTorch ç²¾ç¡®çš„æ—¶é—´åŒæ­¥å‡½æ•°
    # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ CUDAï¼ˆå³ GPUï¼‰è®¾å¤‡
    if torch.cuda.is_available():
        # å¦‚æœæœ‰å¯ç”¨çš„ CUDA è®¾å¤‡ï¼Œåˆ™åŒæ­¥å½“å‰ GPU çš„çŠ¶æ€
        # è¿™å°†ç¡®ä¿åœ¨è°ƒç”¨æ­¤å‡½æ•°ä¹‹å‰ï¼Œæ‰€æœ‰å…ˆå‰çš„ CUDA æ“ä½œéƒ½å·²å®Œæˆ
        torch.cuda.synchronize()

        # è¿”å›å½“å‰çš„ç³»ç»Ÿæ—¶é—´ï¼ˆä»¥ç§’ä¸ºå•ä½ï¼‰
    return time.time()  # ä½¿ç”¨ time.time() è·å–å½“å‰æ—¶é—´æˆ³


def profile(input, ops, n=10, device=None):
    """
    YOLOv5 é€Ÿåº¦/å†…å­˜/FLOPs åˆ†æå™¨ã€‚

    ç”¨æ³•ç¤ºä¾‹ï¼š
    - input = torch.randn(16, 3, 640, 640)  # éšæœºè¾“å…¥
    - m1 = lambda x: x * torch.sigmoid(x)  # è‡ªå®šä¹‰æ“ä½œ
    - m2 = nn.SiLU()  # PyTorch å†…ç½®æ¿€æ´»å‡½æ•°
    - profile(input, [m1, m2], n=100)  # å¯¹ 100 æ¬¡è¿­ä»£è¿›è¡Œåˆ†æ

    å‚æ•°ï¼š
    - input: è¾“å…¥å¼ é‡æˆ–å¼ é‡åˆ—è¡¨ã€‚
    - ops: è¦åˆ†æçš„æ“ä½œæˆ–æ“ä½œåˆ—è¡¨ã€‚
    - n: æ¯ä¸ªæ“ä½œåˆ†æçš„è¿­ä»£æ¬¡æ•°ï¼Œé»˜è®¤ä¸º 10ã€‚
    - device: è¿è¡Œåˆ†æçš„è®¾å¤‡ï¼Œé»˜è®¤ä¸º Noneï¼Œå°†è‡ªåŠ¨é€‰æ‹©ã€‚

    è¿”å›ï¼š
    - ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªæ“ä½œçš„å‚æ•°æ•°é‡ã€FLOPsã€å†…å­˜ä½¿ç”¨ã€å‰å‘æ—¶é—´ã€åå‘æ—¶é—´å’Œè¾“å…¥è¾“å‡ºå½¢çŠ¶ã€‚
    """
    results = []  # ç”¨äºå­˜å‚¨åˆ†æç»“æœ
    logging.basicConfig(format="%(message)s", level=logging.INFO)  # é…ç½®æ—¥å¿—æ ¼å¼
    device = device or select_device()  # é€‰æ‹©è®¾å¤‡
    print(f"{'Params':>12s}{'GFLOPs':>12s}{'GPU_mem (GB)':>14s}{'forward (ms)':>14s}{'backward (ms)':>14s}"
          f"{'input':>24s}{'output':>24s}")  # æ‰“å°è¡¨å¤´

    # ç¡®ä¿è¾“å…¥æ˜¯å¼ é‡åˆ—è¡¨
    for x in input if isinstance(input, list) else [input]:
        x = x.to(device)  # å°†è¾“å…¥è½¬ç§»åˆ°æŒ‡å®šè®¾å¤‡
        x.requires_grad = True  # å…è®¸è®¡ç®—æ¢¯åº¦

        # ç¡®ä¿æ“ä½œæ˜¯æ“ä½œåˆ—è¡¨
        for m in ops if isinstance(ops, list) else [ops]:
            m = m.to(device) if hasattr(m, 'to') else m  # è½¬ç§»æ“ä½œåˆ°æŒ‡å®šè®¾å¤‡
            m = m.half() if hasattr(m, 'half') and isinstance(x, torch.Tensor) and x.dtype is torch.float16 else m
            tf, tb, t = 0., 0., [0., 0., 0.]  # åˆå§‹åŒ–å‰å‘ã€åå‘æ—¶é—´

            try:
                # è®¡ç®— FLOPs
                flops = thop.profile(m, inputs=(x,), verbose=False)[0] / 1E9 * 2  # è½¬ä¸º GFLOPs
            except:
                flops = 0

            try:
                for _ in range(n):
                    t[0] = time_sync()  # å¼€å§‹æ—¶é—´
                    y = m(x)  # å‰å‘ä¼ æ’­
                    t[1] = time_sync()  # ç»“æŸå‰å‘æ—¶é—´
                    try:
                        _ = (sum([yi.sum() for yi in y]) if isinstance(y, list) else y).sum().backward()  # åå‘ä¼ æ’­
                        t[2] = time_sync()  # ç»“æŸåå‘æ—¶é—´
                    except Exception as e:  # å¦‚æœæ²¡æœ‰åå‘ä¼ æ’­æ–¹æ³•
                        print(e)
                        t[2] = float('nan')  # è®°å½•ä¸º NaN
                    tf += (t[1] - t[0]) * 1000 / n  # æ¯æ¬¡å‰å‘æ“ä½œçš„æ—¶é—´
                    tb += (t[2] - t[1]) * 1000 / n  # æ¯æ¬¡åå‘æ“ä½œçš„æ—¶é—´

                mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0  # è·å– GPU å†…å­˜ä½¿ç”¨ï¼ˆGBï¼‰
                s_in = tuple(x.shape) if isinstance(x, torch.Tensor) else 'list'  # è¾“å…¥å½¢çŠ¶
                s_out = tuple(y.shape) if isinstance(y, torch.Tensor) else 'list'  # è¾“å‡ºå½¢çŠ¶
                p = sum(list(x.numel() for x in m.parameters())) if isinstance(m, nn.Module) else 0  # è®¡ç®—å‚æ•°æ€»æ•°

                # æ‰“å°ç»“æœ
                print(f'{p:12}{flops:12.4g}{mem:>14.3f}{tf:14.4g}{tb:14.4g}{str(s_in):>24s}{str(s_out):>24s}')
                results.append([p, flops, mem, tf, tb, s_in, s_out])  # å°†ç»“æœæ·»åŠ åˆ°åˆ—è¡¨
            except Exception as e:
                print(e)
                results.append(None)  # è®°å½•é”™è¯¯
            torch.cuda.empty_cache()  # æ¸…ç©ºç¼“å­˜
    return results  # è¿”å›åˆ†æç»“æœ


def is_parallel(model):
    """
    æ£€æŸ¥æ¨¡å‹æ˜¯å¦ä¸ºæ•°æ®å¹¶è¡Œï¼ˆDPï¼‰æˆ–åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œï¼ˆDDPï¼‰ç±»å‹ã€‚

    å‚æ•°ï¼š
    - model: è¦æ£€æŸ¥çš„æ¨¡å‹å®ä¾‹ã€‚

    è¿”å›ï¼š
    - å¦‚æœæ¨¡å‹æ˜¯ DataParallel æˆ– DistributedDataParallel ç±»å‹ï¼Œåˆ™è¿”å› Trueï¼›å¦åˆ™è¿”å› Falseã€‚
    """
    return type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel)


def de_parallel(model):
    """
    å»é™¤æ¨¡å‹çš„å¹¶è¡ŒåŒ–ï¼šå¦‚æœæ¨¡å‹æ˜¯ DP æˆ– DDP ç±»å‹ï¼Œåˆ™è¿”å›å• GPU æ¨¡å‹ã€‚

    å‚æ•°ï¼š
    - model: è¦å»å¹¶è¡ŒåŒ–çš„æ¨¡å‹å®ä¾‹ã€‚

    è¿”å›ï¼š
    - è¿”å›å»å¹¶è¡ŒåŒ–åçš„æ¨¡å‹ã€‚å¦‚æœæ¨¡å‹ä¸æ˜¯å¹¶è¡ŒåŒ–ç±»å‹ï¼Œåˆ™è¿”å›åŸæ¨¡å‹ã€‚
    """
    return model.module if is_parallel(model) else model



def intersect_dicts(da, db, exclude=()):
    # è·å–ä¸¤ä¸ªå­—å…¸ä¸­åŒ¹é…é”®å’Œå½¢çŠ¶çš„äº¤é›†ï¼Œçœç•¥ 'exclude' é”®ï¼Œä½¿ç”¨ da çš„å€¼
    return {k: v for k, v in da.items()  # éå†å­—å…¸ da çš„é”®å€¼å¯¹
            if k in db  # ä»…ä¿ç•™åœ¨å­—å…¸ db ä¸­å­˜åœ¨çš„é”®
            and not any(x in k for x in exclude)  # æ’é™¤åŒ…å«ä»»ä½• exclude ä¸­å…ƒç´ çš„é”®
            and v.shape == db[k].shape}  # ä»…ä¿ç•™å½¢çŠ¶ä¸å­—å…¸ db ä¸­ç›¸åº”å€¼ç›¸åŒçš„é”®å€¼å¯¹



def initialize_weights(model):
    """
    åˆå§‹åŒ–æ¨¡å‹çš„æƒé‡ã€‚

    å‚æ•°ï¼š
    - model: è¦åˆå§‹åŒ–çš„æ¨¡å‹å®ä¾‹ã€‚

    è¯¥å‡½æ•°å¯¹æ¨¡å‹çš„å„ä¸ªæ¨¡å—è¿›è¡Œåˆå§‹åŒ–ï¼š
    - å¯¹äºå·ç§¯å±‚ï¼ˆConv2dï¼‰ï¼Œå¯ä»¥é€‰æ‹©ä½¿ç”¨ Kaiming æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–ã€‚
    - å¯¹äºæ‰¹å½’ä¸€åŒ–å±‚ï¼ˆBatchNorm2dï¼‰ï¼Œè®¾ç½® eps å’Œ momentumã€‚
    - å¯¹äºæ¿€æ´»å‡½æ•°ï¼ˆå¦‚ Hardswishã€LeakyReLUã€ReLUã€ReLU6ï¼‰ï¼Œå¯ç”¨ inplace è®¡ç®—ä»¥èŠ‚çœå†…å­˜ã€‚
    """
    for m in model.modules():
        t = type(m)
        if t is nn.Conv2d:
            pass  # å¯ä»¥å–æ¶ˆæ³¨é‡Šä»¥ä½¿ç”¨ Kaiming åˆå§‹åŒ–
            # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
        elif t is nn.BatchNorm2d:
            m.eps = 1e-3
            m.momentum = 0.03
        elif t in [nn.Hardswish, nn.LeakyReLU, nn.ReLU, nn.ReLU6]:
            m.inplace = True


def find_modules(model, mclass=nn.Conv2d):
    """
    æŸ¥æ‰¾ä¸æŒ‡å®šæ¨¡å—ç±»åŒ¹é…çš„å±‚ç´¢å¼•ã€‚

    å‚æ•°ï¼š
    - model: è¦æŸ¥æ‰¾çš„æ¨¡å‹å®ä¾‹ã€‚
    - mclass: éœ€è¦åŒ¹é…çš„æ¨¡å—ç±»ï¼Œé»˜è®¤ä¸º nn.Conv2dã€‚

    è¿”å›ï¼š
    - è¿”å›ä¸ mclass åŒ¹é…çš„å±‚ç´¢å¼•åˆ—è¡¨ã€‚
    """
    return [i for i, m in enumerate(model.module_list) if isinstance(m, mclass)]



def sparsity(model):
    """
    è®¡ç®—æ¨¡å‹çš„å…¨å±€ç¨€ç–åº¦ã€‚

    å‚æ•°ï¼š
    - model: è¦è®¡ç®—ç¨€ç–åº¦çš„æ¨¡å‹å®ä¾‹ã€‚

    è¿”å›ï¼š
    - è¿”å›æ¨¡å‹çš„å…¨å±€ç¨€ç–åº¦ï¼Œè®¡ç®—æ–¹å¼ä¸ºé›¶æƒé‡çš„æ•°é‡ä¸æ€»æƒé‡æ•°é‡çš„æ¯”ç‡ã€‚
    """
    a, b = 0., 0.
    for p in model.parameters():
        a += p.numel()  # æ€»æƒé‡æ•°é‡
        b += (p == 0).sum()  # é›¶æƒé‡çš„æ•°é‡
    return b / a  # è¿”å›ç¨€ç–åº¦


def prune(model, amount=0.3):
    """
    å¯¹æ¨¡å‹è¿›è¡Œå‰ªæä»¥è¾¾åˆ°è¯·æ±‚çš„å…¨å±€ç¨€ç–åº¦ã€‚

    å‚æ•°ï¼š
    - model: è¦è¿›è¡Œå‰ªæçš„æ¨¡å‹å®ä¾‹ã€‚
    - amount: è¯·æ±‚çš„å‰ªææ¯”ä¾‹ï¼Œé»˜è®¤ä¸º 0.3ï¼ˆå³ 30% çš„æƒé‡å°†è¢«å‰ªæï¼‰ã€‚

    è¯¥å‡½æ•°éå†æ¨¡å‹ä¸­çš„æ‰€æœ‰å·ç§¯å±‚ï¼Œæ‰§è¡Œ L1 éç»“æ„åŒ–å‰ªæï¼Œå¹¶ç§»é™¤å‰ªææ©ç ä»¥ä½¿æ›´æ”¹æ°¸ä¹…ç”Ÿæ•ˆã€‚
    """
    import torch.nn.utils.prune as prune
    print('Pruning model... ', end='')
    for name, m in model.named_modules():
        if isinstance(m, nn.Conv2d):
            prune.l1_unstructured(m, name='weight', amount=amount)  # æ‰§è¡Œå‰ªæ
            prune.remove(m, 'weight')  # ç§»é™¤å‰ªææ©ç ï¼Œä½¿å…¶æ°¸ä¹…ç”Ÿæ•ˆ
    print(' %.3g global sparsity' % sparsity(model))  # æ‰“å°å‰ªæåçš„å…¨å±€ç¨€ç–åº¦


def fuse_conv_and_bn(conv, bn):
    """
    å°†å·ç§¯å±‚å’Œæ‰¹å½’ä¸€åŒ–å±‚èåˆä¸ºä¸€ä¸ªå·ç§¯å±‚ã€‚

    å‚æ•°ï¼š
    - conv: å¾…èåˆçš„å·ç§¯å±‚ï¼ˆnn.Conv2d å®ä¾‹ï¼‰ã€‚
    - bn: å¾…èåˆçš„æ‰¹å½’ä¸€åŒ–å±‚ï¼ˆnn.BatchNorm2d å®ä¾‹ï¼‰ã€‚

    è¿”å›ï¼š
    - è¿”å›èåˆåçš„å·ç§¯å±‚ï¼ˆnn.Conv2d å®ä¾‹ï¼‰ï¼Œå…¶ä¸­åŒ…å«äº†æ‰¹å½’ä¸€åŒ–çš„å½±å“ã€‚

    èåˆè¿‡ç¨‹å‚è€ƒï¼š
    - https://tehnokv.com/posts/fusing-batchnorm-and-conv/
    """
    # åˆ›å»ºæ–°çš„å·ç§¯å±‚ï¼Œè®¾ç½®ä¸ºæ— æ¢¯åº¦
    fusedconv = nn.Conv2d(
        conv.in_channels,
        conv.out_channels,
        kernel_size=conv.kernel_size,
        stride=conv.stride,
        padding=conv.padding,
        groups=conv.groups,
        bias=True
    ).requires_grad_(False).to(conv.weight.device)

    # å‡†å¤‡å·ç§¯å±‚çš„æƒé‡
    w_conv = conv.weight.clone().view(conv.out_channels, -1)  # å±•å¹³å·ç§¯æƒé‡
    w_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps + bn.running_var)))  # è®¡ç®—æ‰¹å½’ä¸€åŒ–æƒé‡çš„å¯¹è§’çŸ©é˜µ
    fusedconv.weight.copy_(torch.mm(w_bn, w_conv).view(fusedconv.weight.shape))  # èåˆæƒé‡

    # å‡†å¤‡ç©ºé—´åç½®
    b_conv = torch.zeros(conv.weight.size(0), device=conv.weight.device) if conv.bias is None else conv.bias
    b_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))  # è®¡ç®—æ‰¹å½’ä¸€åŒ–åçš„åç½®
    fusedconv.bias.copy_(torch.mm(w_bn, b_conv.reshape(-1, 1)).reshape(-1) + b_bn)  # èåˆåç½®

    return fusedconv  # è¿”å›èåˆåçš„å·ç§¯å±‚



def model_info(model, verbose=False, img_size=640):
    """
    è¾“å‡ºæ¨¡å‹ä¿¡æ¯ï¼ŒåŒ…æ‹¬å‚æ•°æ•°é‡ã€å¯è®­ç»ƒå‚æ•°æ•°é‡å’ŒFLOPsã€‚

    å‚æ•°ï¼š
    - model: å¾…åˆ†æçš„æ¨¡å‹ï¼ˆnn.Module å®ä¾‹ï¼‰ã€‚
    - verbose: æ˜¯å¦è¯¦ç»†è¾“å‡ºæ¯å±‚çš„ä¿¡æ¯ï¼ˆå¸ƒå°”å€¼ï¼‰ã€‚
    - img_size: è¾“å…¥å›¾åƒçš„å°ºå¯¸ï¼Œå¯ä»¥æ˜¯æ•´æ•°æˆ–åˆ—è¡¨ï¼ˆä¾‹å¦‚ï¼Œ640 æˆ– [640, 320]ï¼‰ã€‚

    è¿”å›ï¼š
    - None: ç›´æ¥æ‰“å°æ¨¡å‹çš„æ‘˜è¦ä¿¡æ¯ã€‚
    """
    n_p = sum(x.numel() for x in model.parameters())  # æ€»å‚æ•°æ•°é‡
    n_g = sum(x.numel() for x in model.parameters() if x.requires_grad)  # å¯è®­ç»ƒå‚æ•°æ•°é‡

    if verbose:
        print('%5s %40s %9s %12s %20s %10s %10s' % ('layer', 'name', 'gradient', 'parameters', 'shape', 'mu', 'sigma'))
        for i, (name, p) in enumerate(model.named_parameters()):
            name = name.replace('module_list.', '')  # å»é™¤æ¨¡å—åˆ—è¡¨å‰ç¼€
            print('%5g %40s %9s %12g %20s %10.3g %10.3g' %
                  (i, name, p.requires_grad, p.numel(), list(p.shape), p.mean(), p.std()))  # æ‰“å°å±‚ä¿¡æ¯

    try:  # è®¡ç®—FLOPs
        from thop import profile
        stride = max(int(model.stride.max()), 32) if hasattr(model, 'stride') else 32  # ç¡®å®šæ­¥å¹…
        img = torch.zeros((1, model.yaml.get('ch', 3), stride, stride), device=next(model.parameters()).device)  # åˆ›å»ºè¾“å…¥å¼ é‡
        flops = profile(deepcopy(model), inputs=(img,), verbose=False)[0] / 1E9 * 2  # è®¡ç®—GFLOPs
        img_size = img_size if isinstance(img_size, list) else [img_size, img_size]  # æ‰©å±•å›¾åƒå°ºå¯¸
        fs = ', %.1f GFLOPs' % (flops * img_size[0] / stride * img_size[1] / stride)  # è®¡ç®—640x640çš„GFLOPs
    except (ImportError, Exception):
        fs = ''  # å¦‚æœå‘ç”Ÿå¼‚å¸¸ï¼Œè®¾ç½®ä¸ºé»˜è®¤å€¼

    LOGGER.info(f"Model Summary: {len(list(model.modules()))} layers, {n_p} parameters, {n_g} gradients{fs}")



def load_classifier(name='resnet101', n=2):
    """
    åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒçš„åˆ†ç±»æ¨¡å‹ï¼Œå¹¶å°†è¾“å‡ºå±‚è°ƒæ•´ä¸º n ç±»è¾“å‡ºã€‚

    å‚æ•°ï¼š
    - name: è¦åŠ è½½çš„æ¨¡å‹åç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼Œé»˜è®¤ä¸º 'resnet101'ã€‚
    - n: è¾“å‡ºç±»åˆ«çš„æ•°é‡ï¼ˆæ•´æ•°ï¼‰ï¼Œé»˜è®¤ä¸º 2ã€‚

    è¿”å›ï¼š
    - model: è°ƒæ•´åçš„æ¨¡å‹ï¼ˆtorchvision.models çš„å®ä¾‹ï¼‰ã€‚
    """
    model = torchvision.models.__dict__[name](pretrained=True)  # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹

    # ResNet æ¨¡å‹çš„å±æ€§
    # input_size = [3, 224, 224]  # è¾“å…¥å¤§å°
    # input_space = 'RGB'  # è¾“å…¥ç©ºé—´
    # input_range = [0, 1]  # è¾“å…¥èŒƒå›´
    # mean = [0.485, 0.456, 0.406]  # å‡å€¼
    # std = [0.229, 0.224, 0.225]  # æ ‡å‡†å·®

    # å°†è¾“å‡ºå±‚è°ƒæ•´ä¸º n ä¸ªç±»åˆ«
    filters = model.fc.weight.shape[1]  # è·å–åŸè¾“å‡ºå±‚çš„ç‰¹å¾æ•°
    model.fc.bias = nn.Parameter(torch.zeros(n), requires_grad=True)  # åˆ›å»ºæ–°çš„åç½®
    model.fc.weight = nn.Parameter(torch.zeros(n, filters), requires_grad=True)  # åˆ›å»ºæ–°çš„æƒé‡
    model.fc.out_features = n  # è®¾ç½®è¾“å‡ºç‰¹å¾æ•°é‡
    return model  # è¿”å›è°ƒæ•´åçš„æ¨¡å‹



def scale_img(img, ratio=1.0, same_shape=False, gs=32):
    """
    æŒ‰ç…§ç»™å®šçš„æ¯”ä¾‹ç¼©æ”¾å›¾åƒï¼Œå¹¶ç¡®ä¿å›¾åƒå°ºå¯¸ä¸º gs çš„å€æ•°ã€‚

    å‚æ•°ï¼š
    - img: è¾“å…¥å›¾åƒå¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, channels, height, width)ã€‚
    - ratio: ç¼©æ”¾æ¯”ä¾‹ï¼Œé»˜è®¤ä¸º 1.0ï¼ˆä¸ç¼©æ”¾ï¼‰ã€‚
    - same_shape: æ˜¯å¦ä¿æŒè¾“å…¥å’Œè¾“å‡ºå›¾åƒçš„å½¢çŠ¶ä¸€è‡´ï¼Œé»˜è®¤ä¸º Falseã€‚
    - gs: å›¾åƒå°ºå¯¸çš„åŸºæ•°ï¼Œé»˜è®¤ä¸º 32ï¼Œç¼©æ”¾åçš„å°ºå¯¸ä¼šè¢«è°ƒæ•´ä¸º gs çš„å€æ•°ã€‚

    è¿”å›ï¼š
    - å¤„ç†åçš„å›¾åƒå¼ é‡ã€‚
    """
    if ratio == 1.0:
        return img  # å¦‚æœæ¯”ä¾‹ä¸º 1.0ï¼Œç›´æ¥è¿”å›åŸå›¾åƒ
    else:
        h, w = img.shape[2:]  # è·å–åŸå›¾åƒçš„é«˜åº¦å’Œå®½åº¦
        s = (int(h * ratio), int(w * ratio))  # è®¡ç®—æ–°çš„å°ºå¯¸
        img = F.interpolate(img, size=s, mode='bilinear', align_corners=False)  # ç¼©æ”¾å›¾åƒ
        if not same_shape:  # å¦‚æœä¸ä¿æŒå½¢çŠ¶ä¸€è‡´ï¼Œè¿›è¡Œå¡«å……/è£å‰ª
            h, w = [math.ceil(x * ratio / gs) * gs for x in (h, w)]  # è°ƒæ•´ä¸º gs çš„å€æ•°
        return F.pad(img, [0, w - s[1], 0, h - s[0]], value=0.447)  # å¡«å……å›¾åƒï¼Œä½¿ç”¨ imagenet å‡å€¼



def copy_attr(a, b, include=(), exclude=()):
    """
    ä»å¯¹è±¡ b å¤åˆ¶å±æ€§åˆ°å¯¹è±¡ aã€‚

    å‚æ•°ï¼š
    - a: ç›®æ ‡å¯¹è±¡ï¼Œå°†æ¥æ”¶å±æ€§ã€‚
    - b: æºå¯¹è±¡ï¼Œå°†æä¾›å±æ€§ã€‚
    - include: ä»…å¤åˆ¶è¿™äº›å±æ€§çš„åç§°ï¼ˆå¯é€‰ï¼‰ã€‚
    - exclude: æ’é™¤è¿™äº›å±æ€§çš„åç§°ï¼ˆå¯é€‰ï¼‰ã€‚
    """
    for k, v in b.__dict__.items():
        # æ£€æŸ¥æ˜¯å¦ä»…åŒ…å«æŒ‡å®šå±æ€§ï¼Œæ˜¯å¦ä»¥ '_' å¼€å¤´ï¼Œæˆ–æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
        if (len(include) and k not in include) or k.startswith('_') or k in exclude:
            continue  # è·³è¿‡ä¸æ»¡è¶³æ¡ä»¶çš„å±æ€§
        else:
            setattr(a, k, v)  # è®¾ç½®ç›®æ ‡å¯¹è±¡çš„å±æ€§



class EarlyStopping:
    # YOLOv5 ç®€å•çš„æ—©åœæœºåˆ¶
    def __init__(self, patience=30):
        self.best_fitness = 0.0  # æœ€ä½³é€‚åº”åº¦ï¼Œä¾‹å¦‚mAP
        self.best_epoch = 0  # æœ€ä½³epoch
        self.patience = patience or float('inf')  # åœ¨é€‚åº”åº¦åœæ­¢æå‡åï¼Œç­‰å¾…çš„epochæ•°
        self.possible_stop = False  # å¯èƒ½åœ¨ä¸‹ä¸€ä¸ªepochåœæ­¢

    def __call__(self, epoch, fitness):
        # åˆ¤æ–­æ˜¯å¦éœ€è¦æ—©åœ
        if fitness >= self.best_fitness:  # >= 0 å…è®¸åœ¨è®­ç»ƒçš„æ—©æœŸé˜¶æ®µé€‚åº”åº¦ä¸ºé›¶
            self.best_epoch = epoch  # æ›´æ–°æœ€ä½³epoch
            self.best_fitness = fitness  # æ›´æ–°æœ€ä½³é€‚åº”åº¦

        delta = epoch - self.best_epoch  # è®¡ç®—æ²¡æœ‰æ”¹è¿›çš„epochæ•°
        self.possible_stop = delta >= (self.patience - 1)  # å¯èƒ½åœ¨ä¸‹ä¸€ä¸ªepochåœæ­¢
        stop = delta >= self.patience  # å¦‚æœè¶…è¿‡è€å¿ƒå€¼ï¼Œåˆ™åœæ­¢è®­ç»ƒ

        if stop:
            LOGGER.info(f'EarlyStopping patience {self.patience} exceeded, stopping training.')  # è®°å½•åœæ­¢ä¿¡æ¯

        return stop  # è¿”å›æ˜¯å¦éœ€è¦åœæ­¢


class ModelEMA:
    """
    Model Exponential Moving Average (EMA) ç±»ï¼Œå‚è€ƒè‡ª https://github.com/rwightman/pytorch-image-modelsã€‚

    è¯¥ç±»ä¿æŒæ¨¡å‹ state_dictï¼ˆå‚æ•°å’Œç¼“å†²åŒºï¼‰çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡ã€‚
    è¿™æ—¨åœ¨å®ç°ç±»ä¼¼äº TensorFlow çš„ https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage çš„åŠŸèƒ½ã€‚
    å¹³æ»‘ç‰ˆæœ¬çš„æƒé‡å¯¹äºæŸäº›è®­ç»ƒæ–¹æ¡ˆçš„è‰¯å¥½è¡¨ç°æ˜¯å¿…è¦çš„ã€‚
    æ­¤ç±»å¯¹åˆå§‹åŒ–é¡ºåºæ•æ„Ÿï¼ŒåŒ…æ‹¬æ¨¡å‹åˆå§‹åŒ–ã€GPU åˆ†é…å’Œåˆ†å¸ƒå¼è®­ç»ƒåŒ…è£…å™¨ã€‚
    """

    def __init__(self, model, decay=0.9999, updates=0):
        """
        åˆå§‹åŒ– ModelEMA å®ä¾‹ã€‚

        å‚æ•°:
        model (torch.nn.Module): éœ€è¦è®¡ç®— EMA çš„æ¨¡å‹ã€‚
        decay (float): æŒ‡æ•°è¡°å‡ç‡ï¼Œé»˜è®¤ä¸º 0.9999ã€‚
        updates (int): EMA æ›´æ–°çš„æ¬¡æ•°ï¼Œé»˜è®¤ä¸º 0ã€‚

        è¯´æ˜:
        - åˆ›å»º EMA çš„æ·±æ‹·è´å¹¶å°†å…¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ã€‚
        - å°†æ›´æ–°æ¬¡æ•°å’Œè¡°å‡å‡½æ•°åˆå§‹åŒ–ä¸ºæŒ‡å®šçš„å€¼ã€‚
        - å°† EMA çš„æ‰€æœ‰å‚æ•°è®¾ç½®ä¸ºä¸éœ€è¦æ¢¯åº¦è®¡ç®—ã€‚
        """
        self.ema = deepcopy(model.module if is_parallel(model) else model).eval()  # FP32 EMA
        # if next(model.parameters()).device.type != 'cpu':
        #     self.ema.half()  # FP16 EMA
        self.updates = updates  # æ›´æ–°æ¬¡æ•°
        self.decay = lambda x: decay * (1 - math.exp(-x / 2000))  # è¡°å‡æŒ‡æ•°æ›²çº¿ï¼ˆå¸®åŠ©æ—©æœŸè®­ç»ƒé˜¶æ®µï¼‰
        for p in self.ema.parameters():
            p.requires_grad_(False)  # ç¦ç”¨æ¢¯åº¦è®¡ç®—

    def update(self, model):
        """
        æ›´æ–° EMA å‚æ•°ã€‚

        å‚æ•°:
        model (torch.nn.Module): å½“å‰æ¨¡å‹å®ä¾‹ï¼Œç”¨äºæ›´æ–° EMA å‚æ•°ã€‚

        è¯´æ˜:
        - è®¡ç®—å½“å‰çš„è¡°å‡å€¼ï¼Œå¹¶ä½¿ç”¨å®ƒæ›´æ–° EMA å‚æ•°ã€‚
        """
        with torch.no_grad():
            self.updates += 1  # æ›´æ–°æ¬¡æ•°åŠ  1
            d = self.decay(self.updates)  # è®¡ç®—å½“å‰è¡°å‡å€¼

            msd = model.module.state_dict() if is_parallel(model) else model.state_dict()  # è·å–æ¨¡å‹çš„ state_dict
            for k, v in self.ema.state_dict().items():
                if v.dtype.is_floating_point:  # å¦‚æœå‚æ•°æ˜¯æµ®ç‚¹å‹
                    v *= d  # æŒ‰è¡°å‡å€¼ç¼©æ”¾ EMA æƒé‡
                    v += (1. - d) * msd[k].detach()  # æ›´æ–° EMA æƒé‡

    def update_attr(self, model, include=(), exclude=('process_group', 'reducer')):
        """
        æ›´æ–° EMA å±æ€§ã€‚

        å‚æ•°:
        model (torch.nn.Module): å½“å‰æ¨¡å‹å®ä¾‹ã€‚
        include (tuple): è¦åŒ…å«çš„å±æ€§åï¼Œé»˜è®¤ä¸ºç©ºå…ƒç»„ã€‚
        exclude (tuple): è¦æ’é™¤çš„å±æ€§åï¼Œé»˜è®¤ä¸º ('process_group', 'reducer')ã€‚

        è¯´æ˜:
        - ä½¿ç”¨ copy_attr å‡½æ•°æ›´æ–° EMA çš„å±æ€§ã€‚
        """
        copy_attr(self.ema, model, include, exclude)  # æ›´æ–° EMA å±æ€§

